{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "In this article, we will use [softmax](https://en.wikipedia.org/wiki/Softmax_function) classifier to build a simple image classification neural network with an accuracy of 32%. In a Softmax classifier, binary logic is generalized and regressed to multiple logic. Softmax classifier will output the probability of the corresponding category.\n",
    "\n",
    "We will first define a softmax classifier, then use the training set of [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) to train the neural network, and finally use the test set to verify the accuracy of the neural network.\n",
    "\n",
    "Letâ€™s get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the previous course [GettingStarted](https://thoughtworksinc.github.io/DeepLearning.scala/demo/GettingStarted.html), we need to introduce each class of DeepLearning.scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <script type=\"text/javascript\">\n",
       "        require.config({\n",
       "  paths: {\n",
       "    d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.17/d3.min',\n",
       "    plotly: 'https://cdn.plot.ly/plotly-1.12.0.min'\n",
       "  },\n",
       "\n",
       "  shim: {\n",
       "    plotly: {\n",
       "      deps: ['d3', 'jquery'],\n",
       "      exports: 'plotly'\n",
       "    }\n",
       "  }\n",
       "});\n",
       "        \n",
       "\n",
       "        require(['plotly'], function(Plotly) {\n",
       "          window.Plotly = Plotly;\n",
       "        });\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                     \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                             \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                      \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                             \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                      \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$plugin.$                                            \n",
       "\n",
       "// import scala.concurrent.ExecutionContext.Implicits.global\n",
       "\n",
       "\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.nd4j.linalg.api.ndarray.INDArray\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.nd4j.linalg.factory.Nd4j\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.DeepLearning\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.feature.Factory\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly.element._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly.layout._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly.JupyterScala._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.future._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.concurrent.Await\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.concurrent.duration.Duration\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.each.Monadic._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscalaz.std.stream._\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// import $ivy.`org.nd4j::nd4s:0.8.0`\n",
    "// import $ivy.`org.nd4j:nd4j-cuda-7.5-platform:0.8.0`\n",
    "import $ivy.`org.nd4j::nd4s:0.8.0`\n",
    "import $ivy.`org.nd4j:nd4j-native-platform:0.8.0`\n",
    "import $ivy.`com.chuusai::shapeless:2.3.2`\n",
    "import $ivy.`org.rauschig:jarchivelib:0.5.0`\n",
    "import $ivy.`com.thoughtworks.deeplearning::plugins-builtins:2.0.1`\n",
    "import $ivy.`org.plotly-scala::plotly-jupyter-scala:0.3.2`\n",
    "import $ivy.`com.thoughtworks.each::each:3.3.1`\n",
    "\n",
    "import $ivy.`com.thoughtworks.each:each_2.11:3.3.1`\n",
    "\n",
    "import $plugin.$ivy.`org.scalamacros:paradise_2.11.11:2.1.0`\n",
    "\n",
    "// import scala.concurrent.ExecutionContext.Implicits.global\n",
    "\n",
    "\n",
    "\n",
    "import org.nd4j.linalg.api.ndarray.INDArray\n",
    "import org.nd4j.linalg.factory.Nd4j\n",
    "import com.thoughtworks.deeplearning.DeepLearning\n",
    "import com.thoughtworks.deeplearning.plugins._\n",
    "import com.thoughtworks.feature.Factory\n",
    "import plotly._\n",
    "import plotly.element._\n",
    "import plotly.layout._\n",
    "import plotly.JupyterScala._\n",
    "plotly.JupyterScala.init()\n",
    "\n",
    "import com.thoughtworks.future._\n",
    "import scala.concurrent.Await\n",
    "import scala.concurrent.duration.Duration\n",
    "import com.thoughtworks.each.Monadic._\n",
    "import scalaz.std.stream._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the line numbers outputted by `jupyter-scala` and to make sure that the page output will not be too long, we need to set `pprintConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprintConfig() = pprintConfig().copy(height = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your own neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate need to be set for the full connection layer. Learning rate visually describes the change rate of `weight`. A too-low learning rate will result in slow decrease of `loss`, which will require longer time for training; A too-high learning rate will result in rapid decrease of `loss` at first while fluctuation around the lowest point afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mINDArrayLearningRatePluginUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://gist.githubusercontent.com/Rabenda/f06279e648e45bd574dc382abb4c44ac/raw/7bd7a871030988c58524108c5985f71002f82012/INDArrayLearningRate.sc\"\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val INDArrayLearningRatePluginUrl = \"https://gist.githubusercontent.com/Rabenda/f06279e648e45bd574dc382abb4c44ac/raw/7bd7a871030988c58524108c5985f71002f82012/INDArrayLearningRate.sc\"\n",
    "interp.load(scala.io.Source.fromURL(new java.net.URL(INDArrayLearningRatePluginUrl)).mkString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mCNNsPluginUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://gist.github.com/Atry/15b7d9a4c63d95ad3d67e94bf20b4f69/raw/59f7ee4dff0dde3753f560633574265e950edc93/CNN.sc\"\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val CNNsPluginUrl = \"https://gist.github.com/Atry/15b7d9a4c63d95ad3d67e94bf20b4f69/raw/59f7ee4dff0dde3753f560633574265e950edc93/CNN.sc\"\n",
    "interp.load(scala.io.Source.fromURL(new java.net.URL(CNNsPluginUrl)).mkString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mL2RegularizationPluginUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://gist.githubusercontent.com/TerrorJack/a60ff752270c40a6485ee787837390aa/raw/119cbacb29dc12d74ae676b4b02687a8f38b02e4/L2Regularization.sc\"\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val L2RegularizationPluginUrl = \"https://gist.githubusercontent.com/TerrorJack/a60ff752270c40a6485ee787837390aa/raw/119cbacb29dc12d74ae676b4b02687a8f38b02e4/L2Regularization.sc\"\n",
    "interp.load(scala.io.Source.fromURL(new java.net.URL(L2RegularizationPluginUrl)).mkString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mAdamPluginUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://gist.githubusercontent.com/Rabenda/0c2fc6ba4cfa536e4788112a94200b50/raw/233cbc83932dad659519c80717d145a3983f57e1/Adam.sc\"\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val AdamPluginUrl = \"https://gist.githubusercontent.com/Rabenda/0c2fc6ba4cfa536e4788112a94200b50/raw/233cbc83932dad659519c80717d145a3983f57e1/Adam.sc\"\n",
    "interp.load(scala.io.Source.fromURL(new java.net.URL(AdamPluginUrl)).mkString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.concurrent.Executors\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.concurrent.ExecutionContext\n",
       "\u001b[39m\n",
       "\u001b[36msingleThreadExecutor\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mutil\u001b[39m.\u001b[32mconcurrent\u001b[39m.\u001b[32mExecutorService\u001b[39m = java.util.concurrent.Executors$FinalizableDelegatedExecutorService@1fb544d8\n",
       "\u001b[36msingleThreadExecutionContext\u001b[39m: \u001b[32mconcurrent\u001b[39m.\u001b[32mExecutionContextExecutor\u001b[39m = scala.concurrent.impl.ExecutionContextImpl@6b3b96df"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.util.concurrent.Executors\n",
    "import scala.concurrent.ExecutionContext\n",
    "val singleThreadExecutor = Executors.newSingleThreadExecutor()\n",
    "implicit val singleThreadExecutionContext = ExecutionContext.fromExecutor(singleThreadExecutor)\n",
    "\n",
    "// , { throwable =>\n",
    "//     println(\"xxxxx\")\n",
    "//     sys.exit(-1)\n",
    "//     throwable.getCause.printStackTrace()\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "// `interp.load` is a workaround for https://github.com/lihaoyi/Ammonite/issues/649 and https://github.com/scala/bug/issues/10390\n",
    "\n",
    "// \n",
    "interp.load(\"\"\"\n",
    "  val hyperparameters = Factory[Builtins with CNNs with L2Regularization  with Adam with INDArrayLearningRate ].\n",
    "   newInstance(learningRate = 1e-4, l2Regularization = 0.000001)\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "// 20%\n",
    "// interp.load(\"\"\"\n",
    "//   val hyperparameters = Factory[Builtins with CNNs with L2Regularization with INDArrayLearningRate].\n",
    "//    newInstance(learningRate = 0.000001, l2Regularization = 0.01)\n",
    "// \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `softmax` classifier (softmax classifier is a neural network combined by `softmax` and a full connection), we first need to write softmax function, formula: ![](https://www.zhihu.com/equation?tex=f_j%28z%29%3D%5Cfrac%7Be%5E%7Bz_j%7D%7D%7B%5Csum_ke%5E%7Bz_k%7D%7D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.implicits._\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyperparameters.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.INDArrayLayer\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36msoftmax\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyperparameters.INDArrayLayer\n",
    "\n",
    "def softmax(scores: INDArrayLayer): INDArrayLayer = {\n",
    "  val expScores = hyperparameters.exp(scores)\n",
    "  (expScores + 1e-8) / (expScores.sum(1) + 1e-8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mfileHandler\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mutil\u001b[39m.\u001b[32mlogging\u001b[39m.\u001b[32mFileHandler\u001b[39m = java.util.logging.FileHandler@3c756a54"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fileHandler = new java.util.logging.FileHandler(\"CNNsmall%g.log\")\n",
    "hyperparameters.logger.addHandler(fileHandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose your  neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a full connection layer and [initialize Weight](https://github.com/ThoughtWorksInc/DeepLearning.scala/wiki/Getting-Started#231--weight-intialization), `Weight` shall be a two-dimension `INDArray` of `NumberOfPixels Ã— NumberOfClasses`. `scores` is the score of each image corresponding to each category, representing the feasible probability of each category corresponding to each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                 \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.etl.Cifar10\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.future._\n",
       "\u001b[39m\n",
       "\u001b[36mcifar10\u001b[39m: \u001b[32mcom\u001b[39m.\u001b[32mthoughtworks\u001b[39m.\u001b[32mdeeplearning\u001b[39m.\u001b[32metl\u001b[39m.\u001b[32mCifar10\u001b[39m = \u001b[33mCifar10\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.thoughtworks.deeplearning.etl::cifar10:1.1.0`\n",
    "import com.thoughtworks.deeplearning.etl.Cifar10\n",
    "import com.thoughtworks.future._\n",
    "val cifar10 = Cifar10.load().blockingAwait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mNumberOfClasses\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m10\u001b[39m\n",
       "\u001b[36mNumberOfPixels\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m3072\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//10 label of CIFAR10 images(airplane,automobile,bird,cat,deer,dog,frog,horse,ship,truck)\n",
    "val NumberOfClasses: Int = 10\n",
    "val NumberOfPixels: Int = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.INDArrayWeight\n",
       "// case class CnnLayer(numberOfFilters: Int, hasPooling: Boolean)\n",
       "\n",
       "// // val cnnLayers: Array[CnnLayer] = Array(\n",
       "// //     CnnLayer(16, hasPooling = true),\n",
       "// //     CnnLayer(18, hasPooling = true),\n",
       "// //     CnnLayer(20, hasPooling = false),\n",
       "// //     CnnLayer(22, hasPooling = true),\n",
       "// //     CnnLayer(24, hasPooling = true)\n",
       "// // )\n",
       "\n",
       "// val cnnLayers: Array[CnnLayer] = Array(\n",
       "//     CnnLayer(64, hasPooling = false),\n",
       "//     CnnLayer(64, hasPooling = true),\n",
       "//     CnnLayer(128, hasPooling = false),\n",
       "//     CnnLayer(128, hasPooling = true),\n",
       "//     CnnLayer(256, hasPooling = false),\n",
       "//     CnnLayer(256, hasPooling = true)\n",
       "// )\n",
       "\n",
       "// val lastCnnWidth = cnnLayers.foldLeft(defaultPixelSize) { (width, cnnLayerConfigure) =>\n",
       "//     if (cnnLayerConfigure.hasPooling) {\n",
       "//     assert(width > 1)\n",
       "//         width / 2\n",
       "//     } else {\n",
       "//         width\n",
       "//     }\n",
       "// }\n",
       "// val outputPixel = cnnLayers.last.numberOfFilters * lastCnnWidth * lastCnnWidth\n",
       "\n",
       "// final case class Model(cnnLayerParameters: Seq[CnnLayerParameter],\n",
       "//                        fullConnectedWeight: INDArrayWeight,\n",
       "//                        fullConnectedBias: INDArrayWeight) \n",
       "\n",
       "// final case class CnnLayerParameter(weight: INDArrayWeight, bias: INDArrayWeight)\n",
       "\n",
       "// def isExistVersion(version: Int): Boolean = {\n",
       "//     import ammonite.ops._\n",
       "//     val filePath = pwd / \"backup\" / version.toString\n",
       "//     exists(filePath)\n",
       "// }\u001b[39m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyperparameters.INDArrayWeight\n",
    "// case class CnnLayer(numberOfFilters: Int, hasPooling: Boolean)\n",
    "\n",
    "// // val cnnLayers: Array[CnnLayer] = Array(\n",
    "// //     CnnLayer(16, hasPooling = true),\n",
    "// //     CnnLayer(18, hasPooling = true),\n",
    "// //     CnnLayer(20, hasPooling = false),\n",
    "// //     CnnLayer(22, hasPooling = true),\n",
    "// //     CnnLayer(24, hasPooling = true)\n",
    "// // )\n",
    "\n",
    "// val cnnLayers: Array[CnnLayer] = Array(\n",
    "//     CnnLayer(64, hasPooling = false),\n",
    "//     CnnLayer(64, hasPooling = true),\n",
    "//     CnnLayer(128, hasPooling = false),\n",
    "//     CnnLayer(128, hasPooling = true),\n",
    "//     CnnLayer(256, hasPooling = false),\n",
    "//     CnnLayer(256, hasPooling = true)\n",
    "// )\n",
    "\n",
    "// val lastCnnWidth = cnnLayers.foldLeft(defaultPixelSize) { (width, cnnLayerConfigure) =>\n",
    "//     if (cnnLayerConfigure.hasPooling) {\n",
    "//     assert(width > 1)\n",
    "//         width / 2\n",
    "//     } else {\n",
    "//         width\n",
    "//     }\n",
    "// }\n",
    "// val outputPixel = cnnLayers.last.numberOfFilters * lastCnnWidth * lastCnnWidth\n",
    "\n",
    "// final case class Model(cnnLayerParameters: Seq[CnnLayerParameter],\n",
    "//                        fullConnectedWeight: INDArrayWeight,\n",
    "//                        fullConnectedBias: INDArrayWeight) \n",
    "\n",
    "// final case class CnnLayerParameter(weight: INDArrayWeight, bias: INDArrayWeight)\n",
    "\n",
    "// def isExistVersion(version: Int): Boolean = {\n",
    "//     import ammonite.ops._\n",
    "//     val filePath = pwd / \"backup\" / version.toString\n",
    "//     exists(filePath)\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// def writeWeightsAndBias(version: Int, model: Model): Unit = {\n",
    "//     import ammonite.ops._\n",
    "    \n",
    "//     def write(outputFilePath: Path, dataOfWeightOrBias: INDArrayWeight): Unit = {\n",
    "//         import java.io.FileOutputStream\n",
    "//         import java.io.ObjectOutputStream\n",
    "//         val outputStream: ObjectOutputStream = new ObjectOutputStream(new FileOutputStream(outputFilePath.toIO))\n",
    "//         try {\n",
    "//             outputStream.writeObject(dataOfWeightOrBias.data)\n",
    "//         } finally {\n",
    "//             outputStream.close()\n",
    "//         }\n",
    "//     }\n",
    "    \n",
    "//     val Model(cnnLayerParameters, \n",
    "//           fullConnectedWeight,\n",
    "//           fullConnectedBias) = model\n",
    "    \n",
    "        \n",
    "//     for (CnnLayerParameter(weight, bias) <- cnnLayerParameters; index <- cnnLayerParameters.indices) {\n",
    "//         //val CnnLayerParameter(weight, bias) = weightAndBias\n",
    "        \n",
    "//         val filePath = pwd / \"backup\" / version.toString\n",
    "//         val weightFilePath = filePath / s\"weight$index\"\n",
    "//         val biasFilePath = filePath / s\"bais$index\"\n",
    "//         write(weightFilePath, weight)\n",
    "//         write(biasFilePath, bias)\n",
    "\n",
    "//     }\n",
    "    \n",
    "//     val fullConnectedIndex = cnnLayers.length\n",
    "    \n",
    "//     val fullConnectedfilePath = pwd / \"backup\" / version.toString\n",
    "//     val fullConnectedweightFilePath = fullConnectedfilePath / s\"weight$fullConnectedIndex\"\n",
    "//     val fullConnectedbiasFilePath = fullConnectedfilePath / s\"bais$fullConnectedIndex\"\n",
    "    \n",
    "//     write(fullConnectedweightFilePath, fullConnectedWeight)\n",
    "//     write(fullConnectedbiasFilePath, fullConnectedBias)\n",
    "// }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// def readWeightsAndBias(version: Int): Model = {\n",
    "//     if (isExistVersion(version) == false) {\n",
    "//         throw new IllegalArgumentException(s\"The version$version isn't exist!\")\n",
    "//     }\n",
    "    \n",
    "//     import ammonite.ops._\n",
    "    \n",
    "//     def read(inputFilePath: Path): INDArrayWeight = {\n",
    "//         import java.io.FileInputStream\n",
    "//         import java.io.ObjectInputStream\n",
    "//         val inputStream: ObjectInputStream = new ObjectInputStream(new FileInputStream(inputFilePath.toIO))\n",
    "//         try {\n",
    "//             INDArrayWeight(inputStream.readObject().asInstanceOf[INDArray])\n",
    "//         } finally {\n",
    "//             inputStream.close()\n",
    "//         }\n",
    "//     }\n",
    "    \n",
    "//     val cnnLayerParameter = for (index <- cnnLayers.indices) yield {\n",
    "//         val filePath = pwd / \"backup\" / version.toString\n",
    "//         val weightFilePath = filePath / s\"weight$index\"\n",
    "//         val biasFilePath = filePath / s\"bais$index\"\n",
    "//         val weight = read(weightFilePath)\n",
    "//         val bias = read(biasFilePath)\n",
    "//         CnnLayerParameter(weight, bias)\n",
    "//     }\n",
    "//     val fullConnectedIndex = cnnLayers.length\n",
    "    \n",
    "//     val fullConnectedfilePath = pwd / \"backup\" / version.toString\n",
    "//     val fullConnectedweightFilePath = fullConnectedfilePath / s\"weight$fullConnectedIndex\"\n",
    "//     val fullConnectedbiasFilePath = fullConnectedfilePath / s\"bais$fullConnectedIndex\"\n",
    "    \n",
    "//     val fullConnectedWeight = read(fullConnectedweightFilePath)\n",
    "//     val fullConnectedBias = read(fullConnectedbiasFilePath)\n",
    "    \n",
    "//     Model(cnnLayerParameter, fullConnectedWeight, fullConnectedBias)\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// def initializeWeightAndBias(version: Int): Model = {\n",
    "//     import org.nd4s.Implicits._\n",
    "//     def NumberOfChannels = 3 // magic Number\n",
    "//     def loadWeightAndBias() = {\n",
    "//         readWeightsAndBias(version)\n",
    "//     }\n",
    "\n",
    "//     def randomlyInitializeWeightAndBias() = {\n",
    "        \n",
    "//         val cnnLayerParameter = for (i <- cnnLayers.indices) yield {\n",
    "//             val inputDepth = if (i == 0) {\n",
    "//                 NumberOfChannels\n",
    "//             } else {\n",
    "//                 cnnLayers(i - 1).numberOfFilters\n",
    "//             }\n",
    "            \n",
    "\n",
    "//             val numberOfFilters = cnnLayers(i).numberOfFilters\n",
    "//             val weight = INDArrayWeight(\n",
    "//                 Nd4j.randn(\n",
    "//                     Array(numberOfFilters, \n",
    "//                     inputDepth, \n",
    "//                     KernelWidth, \n",
    "//                     KernelHeight)\n",
    "//                 ) / math.sqrt(inputDepth * KernelWidth * KernelHeight / 2))\n",
    "            \n",
    "//             val bias = INDArrayWeight(Nd4j.zeros(numberOfFilters))\n",
    "            \n",
    "//             CnnLayerParameter(weight, bias)\n",
    "//         }\n",
    "        \n",
    "//         val numberOfFilters = cnnLayers.last.numberOfFilters\n",
    "//         val fullConnectedWeight = INDArrayWeight(Nd4j.randn(Array(outputPixel, Cifar10.NumberOfClasses)) / math.sqrt(outputPixel / 2))\n",
    "//         val fullConnectedBias = INDArrayWeight(Nd4j.zeros(Cifar10.NumberOfClasses))\n",
    "//         Model(cnnLayerParameter, fullConnectedWeight, fullConnectedBias)\n",
    "//     }\n",
    "    \n",
    "//     if (isExistVersion(version)) {\n",
    "//         loadWeightAndBias()\n",
    "//     } else {\n",
    "//         randomlyInitializeWeightAndBias()\n",
    "//     }\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// val currentVersion = 0\n",
    "// val model = initializeWeightAndBias(currentVersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// for (CnnLayerParameter(weight, bias) <- model.cnnLayerParameters) {\n",
    "//     hyperparameters.logger.info(s\"${weight.data.shape.toSeq} ${bias.data.shape.toSeq}\")\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// def dropOut(layer: INDArrayLayer, p: Double): INDArrayLayer = {\n",
    "//     import com.thoughtworks.raii.asynchronous._\n",
    "//     import scalaz.syntax.all._\n",
    "//     import com.thoughtworks.deeplearning.DeepLearning.Tape\n",
    "// //     import org.nd4j.linalg.api.ndarray.INDArray._\n",
    "// //     import org.nd4s.Implicits._\n",
    "//     val doTape: Do[Tape[INDArray, INDArray]] = layer.forward.flatMap { tape: Tape[INDArray, INDArray] =>\n",
    "//         (layer * (Nd4j.randn(tape.data.shape) gt p)).forward\n",
    "//     }\n",
    "//     INDArrayLayer(doTape)\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// def dropOut(layer: INDArrayLayer, p: Double): INDArrayLayer = INDArrayLayer(monadic[Do] {\n",
    "//     (layer * (Nd4j.randn(layer.forward.each.data.shape) > p)).forward.each\n",
    "// })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mKernelSize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m7\u001b[39m\n",
       "\u001b[36mKernelWidth\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m7\u001b[39m\n",
       "\u001b[36mKernelHeight\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m7\u001b[39m\n",
       "\u001b[36mNumFilters\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m32\u001b[39m\n",
       "\u001b[36mHiddenDim\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m500\u001b[39m\n",
       "\u001b[36mWeightScale\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.01\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mPixelHeight\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mPixelWidth\u001b[39m\n",
       "\u001b[36mPadding\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m3\u001b[39m\n",
       "\u001b[36mStride\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m1\u001b[39m\n",
       "\u001b[36mPoolSize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m2\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val KernelSize: Int = 7\n",
    "val KernelWidth: Int = KernelSize\n",
    "val KernelHeight: Int = KernelSize\n",
    "\n",
    "val NumFilters: Int = 32\n",
    "val HiddenDim: Int = 500 //define hidden_layer->affineRuleOfCnnLayer\n",
    "val WeightScale: Double = 1e-2 //0.001\n",
    "// def defaultPixelSize = Cifar10.Width\n",
    "def PixelHeight = Cifar10.Height\n",
    "def PixelWidth = Cifar10.Width\n",
    "val Padding: Int = (KernelSize - 1) / 2\n",
    "val Stride: Int = 1\n",
    "val PoolSize: Int = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mobject\u001b[39m \u001b[36mAllWeightsAndBias\u001b[39m"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object AllWeightsAndBias {\n",
    "    import org.nd4s.Implicits._\n",
    "    val cnnWeight: INDArrayWeight = INDArrayWeight(Nd4j.randn(Array(NumFilters, Cifar10.NumberOfChannels, KernelHeight, KernelWidth)) * WeightScale)\n",
    "    val cnnBias: INDArrayWeight = INDArrayWeight(Nd4j.zeros(NumFilters))\n",
    "    val affineWeight: INDArrayWeight = INDArrayWeight(Nd4j.randn(Array(NumFilters * (PixelHeight / PoolSize) * (PixelWidth / PoolSize), HiddenDim)) * WeightScale)\n",
    "    val affineBias: INDArrayWeight = INDArrayWeight(Nd4j.zeros(HiddenDim))\n",
    "    val affineLastWeight: INDArrayWeight = INDArrayWeight(Nd4j.randn(Array(HiddenDim, Cifar10.NumberOfClasses)) * WeightScale)\n",
    "    val affineLastBias: INDArrayWeight = INDArrayWeight(Nd4j.zeros(Cifar10.NumberOfClasses))\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mAllWeightsAndBias._\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import AllWeightsAndBias._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36maffine\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mrelu\u001b[39m"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def affine(input: INDArrayLayer, weight: INDArrayWeight, bias: INDArrayWeight): INDArrayLayer = {\n",
    "    input dot weight + bias\n",
    "}\n",
    "\n",
    "def relu(input: INDArrayLayer): INDArrayLayer = {\n",
    "    import hyperparameters.max\n",
    "    max(input, 0.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mmyNeuralNetwork\u001b[39m"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "// def __init__(self, input_dim=(3, 32, 32), num_filters=32, filter_size=7,\n",
    "//                hidden_dim=100, num_classes=10, weight_scale=1e-3, reg=0.0,\n",
    "//                dtype=np.float32):\n",
    "\n",
    "//     C, H, W = input_dim\n",
    "//     F, HH, WW = num_filters, filter_size, filter_size\n",
    "//     self.params['W1'] = weight_scale * np.random.randn(F, C, HH, WW)\n",
    "//     self.params['W2'] = weight_scale * np.random.randn(F*H/2*W/2, hidden_dim)\n",
    "//     self.params['W3'] = weight_scale * np.random.randn(hidden_dim, num_classes)\n",
    "//     self.params['b1'] = np.zeros(F)\n",
    "//     self.params['b2'] = np.zeros(hidden_dim)\n",
    "//     self.params['b3'] = np.zeros(num_classes)\n",
    "\n",
    "// INDArrayWeight(Nd4j.randn(\n",
    "//                     Array(numberOfFilters, \n",
    "//                     inputDepth, \n",
    "//                     KernelWidth, \n",
    "//                     KernelHeight)\n",
    "//                 ) / math.sqrt(inputDepth * KernelWidth * KernelHeight / 2))\n",
    "\n",
    "def myNeuralNetwork(input: INDArray):  INDArrayLayer = {\n",
    "    import hyperparameters.max\n",
    "    import hyperparameters.maxPool\n",
    "    import hyperparameters.conv2d\n",
    "    \n",
    "    val cnnLayer = maxPool(relu(conv2d(input.reshape(input.shape()(0), Cifar10.NumberOfChannels, PixelHeight, PixelWidth), cnnWeight, cnnBias, (KernelHeight, KernelWidth), (Stride, Stride), (Padding, Padding))), (PoolSize, PoolSize))\n",
    "\n",
    "    val affineRuleOfCnnLayer = relu(affine(cnnLayer.reshape(input.shape()(0), NumFilters * (PixelHeight / PoolSize) * (PixelWidth / PoolSize)), affineWeight, affineBias))\n",
    "\n",
    "    val affineOfaffineRuleOfCnnLayer = affine(affineRuleOfCnnLayer.reshape(input.shape()(0), HiddenDim), affineLastWeight, affineLastBias)\n",
    "\n",
    "    val softmaxValue = softmax(affineOfaffineRuleOfCnnLayer)\n",
    "\n",
    "    softmaxValue\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// def myNeuralNetwork(input: INDArray):  INDArrayLayer = {\n",
    "//     import hyperparameters.max\n",
    "//     import hyperparameters.maxPool\n",
    "//     import hyperparameters.conv2d\n",
    "    \n",
    "//     val Model(cnnLayerParameters, fullConnectedWeight, fullConnectedBias) = model\n",
    "    \n",
    "//     def loop(i: Int): INDArrayLayer = {\n",
    "//         val CnnLayerParameter(weight, bias) = cnnLayerParameters(i)\n",
    "//         val cnnLayer = if (i == 0) {\n",
    "//             max(conv2d(input, weight, bias, (3, 3), (1, 1), (1, 1)), 0.0)\n",
    "//         } else {\n",
    "//             max(conv2d(loop(i - 1), weight, bias, (3, 3), (1, 1), (1, 1)), 0.0)\n",
    "//         }\n",
    "//         if (cnnLayers(i).hasPooling) {\n",
    "//             maxPool(cnnLayer, (2, 2))\n",
    "//         } else {\n",
    "//             cnnLayer\n",
    "//         }\n",
    "//     }\n",
    "    \n",
    "//     val layer6 = loop(5)\n",
    "    \n",
    "    \n",
    "//     // ??? Width ?= Height\n",
    "//     val layer6DropOut = dropOut(layer6, 0.5)\n",
    "//     val layer7 = layer6DropOut.reshape(input.shape.head, outputPixel) dot fullConnectedWeight + fullConnectedBias\n",
    "//     softmax(layer7)\n",
    "// }\n",
    "\n",
    "\n",
    "// def myNeuralNetwork(input: INDArray): INDArrayLayer = {\n",
    "//     import hyperparameters.max\n",
    "//     import hyperparameters.maxPool\n",
    "//     import hyperparameters.conv2d\n",
    "//     val layer1 = maxPool(max(conv2d(input.reshape(input.shape()(0), 3, 32, 32), weight1, bias1, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
    "//     val layer2 = maxPool(max(conv2d(layer1, weight2, bias2, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
    "//     val layer3 = maxPool(max(conv2d(layer2, weight3, bias3, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
    "//     val layer4 = maxPool(max(conv2d(layer3, weight4, bias4, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
    "//     val layer5 = maxPool(max(conv2d(layer4, weight5, bias5, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
    "\n",
    "//     val layer6 = layer5.reshape(input.shape()(0), 24) dot weight6 + bias6\n",
    "//     softmax(layer6)\n",
    "// }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LossFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn about the prediction result of the neural network, we need to write the loss function `lossFunction`. We use [cross-entropy loss](https://en.wikipedia.org/wiki/Cross_entropy) to make comparison between this result and the actual result before return the score. Formula:\n",
    "![](https://zhihu.com/equation?tex=%5Cdisplaystyle+H%28p%2Cq%29%3D-%5Csum_xp%28x%29+logq%28x%29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.DoubleLayer\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mlossFunction\u001b[39m"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyperparameters.DoubleLayer\n",
    "\n",
    "def lossFunction(input: INDArray, expectOutput: INDArray): DoubleLayer = {\n",
    "\n",
    "    \n",
    "    val probabilities = myNeuralNetwork(input)\n",
    "    val result = -(hyperparameters.log(probabilities) * expectOutput).mean\n",
    "    \n",
    "    result\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the images and corresponding label information for test data from CIFAR10 database and process them, we need [`import $file.ReadCIFAR10ToNDArray`](https://github.com/ThoughtWorksInc/DeepLearning.scala-website/blob/master/ipynbs/ReadCIFAR10ToNDArray.sc). This is a script file containing the read and processed CIFAR10 data, provided in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// import $url.{`https://raw.githubusercontent.com/ThoughtWorksInc/DeepLearning.scala-website/v1.0.0-doc/ipynbs/ReadCIFAR10ToNDArray.sc` => ReadCIFAR10ToNDArray}\n",
    "\n",
    "// val trainNDArray = ReadCIFAR10ToNDArray.readFromResource(\"/cifar-10-batches-bin/data_batch_1.bin\", 1000)\n",
    "\n",
    "// val testNDArray = ReadCIFAR10ToNDArray.readFromResource(\"/cifar-10-batches-bin/test_batch.bin\", 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before passing data to the softmax classifier, we first process label data with ([one hot encoding](https://en.wikipedia.org/wiki/One-hot)): transform INDArray of `NumberOfPixels Ã— 1` into INDArray of `NumberOfPixels Ã— NumberOfClasses`. The value of correct classification corresponding to each line is 1, and the values of other columns are 0. The reason for differentiating the training set and test set is to make it clear that whether the network is over trained which leads to [overfitting](https://en.wikipedia.org/wiki/Overfitting). While processing label data, we used [Utils](https://github.com/ThoughtWorksInc/DeepLearning.scala-website/blob/master/ipynbs/Utils.sc), which is also provided in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// val trainData = trainNDArray.head\n",
    "// val testData = testNDArray.head\n",
    "\n",
    "\n",
    "// val trainExpectResult = trainNDArray.tail.head\n",
    "// val testExpectResult = testNDArray.tail.head\n",
    "\n",
    "// import $url.{`https://raw.githubusercontent.com/ThoughtWorksInc/DeepLearning.scala-website/v1.0.0-doc/ipynbs/Utils.sc` => Utils}\n",
    "\n",
    "// val vectorizedTrainExpectResult = Utils.makeVectorized(trainExpectResult, NumberOfClasses)\n",
    "// val vectorizedTestExpectResult = Utils.makeVectorized(testExpectResult, NumberOfClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To observe the training process of the neural network, we need to output `loss`; while training the neural network, the `loss` shall be decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mTrainer\u001b[39m"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// var lossSeq: IndexedSeq[Double] = IndexedSeq.empty\n",
    "\n",
    "// @monadic[Future]\n",
    "// val trainTask: Future[Unit] = {\n",
    "//   val lossStream = for (_ <- (1 to 2000).toStream) yield {\n",
    "//     val loss = lossFunction(trainData, vectorizedTrainExpectResult).train.each\n",
    "//     kernel.publish.markdown(s\"loss: $loss\")\n",
    "//     loss\n",
    "//   }\n",
    "//   lossSeq = IndexedSeq.concat(lossStream)\n",
    "// }\n",
    "\n",
    "\n",
    "class Trainer(batchSize: Int, numberOfEpoches: Int = 5) {\n",
    "    import scalaz.std.anyVal._\n",
    "    import scalaz.syntax.all._\n",
    "    @volatile\n",
    "    private var isShuttingDown: Boolean = false\n",
    "\n",
    "    private val lossBuffer = scala.collection.mutable.Buffer.empty[Double]\n",
    "        \n",
    "    def plotLoss(): Unit = Seq(Scatter(lossBuffer.indices, lossBuffer)).plot(title = \"loss by time\")\n",
    "    \n",
    "    def interrupt(): Unit = isShuttingDown = true\n",
    "\n",
    "    def startTrain(): Unit = {\n",
    "\n",
    "        @monadic[Future]\n",
    "        def trainTask: Future[Unit] = {\n",
    "            isShuttingDown = false\n",
    "            var epoch = 0\n",
    "            \n",
    "            while (epoch < numberOfEpoches && !isShuttingDown) {\n",
    "                val cifar10 = Cifar10.load().blockingAwait\n",
    "                val iterator = cifar10.epoch(batchSize).zipWithIndex\n",
    "                while (iterator.hasNext && !isShuttingDown) {\n",
    "                    val (Cifar10.Batch(labels, batch), i) = iterator.next()\n",
    "                    val loss = lossFunction(batch, labels).train.each\n",
    "                    lossBuffer += loss\n",
    "                    hyperparameters.logger.info(s\"epoch=$epoch iteration=$i batchSize=$batchSize loss=$loss\")\n",
    "                }\n",
    "                epoch += 1\n",
    "            }\n",
    "            hyperparameters.logger.info(\"Done\")\n",
    "        }\n",
    "        trainTask.onComplete { tryUnit: scala.util.Try[Unit] => tryUnit.get }\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainBatchSize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m50\u001b[39m\n",
       "\u001b[36mtrainer\u001b[39m: \u001b[32mTrainer\u001b[39m = $sess.cmd25Wrapper$Helper$Trainer@381bfd00"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainBatchSize = 50\n",
    "\n",
    "val trainer = new Trainer(batchSize = trainBatchSize, numberOfEpoches = 1)\n",
    "trainer.startTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// trainer.interrupt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"chart\" id=\"plot-1746384081\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "requirejs([\"plotly\"], function(Plotly) {\n",
       "  (function () {\n",
       "  var data0 = {\"type\":\"scatter\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0,51.0,52.0,53.0,54.0,55.0,56.0,57.0,58.0,59.0,60.0,61.0,62.0,63.0,64.0,65.0,66.0,67.0,68.0,69.0,70.0,71.0,72.0,73.0,74.0,75.0,76.0,77.0,78.0,79.0,80.0,81.0,82.0,83.0,84.0,85.0,86.0,87.0,88.0,89.0,90.0,91.0,92.0,93.0,94.0,95.0,96.0,97.0,98.0,99.0,100.0,101.0,102.0,103.0,104.0,105.0,106.0,107.0,108.0,109.0,110.0,111.0,112.0,113.0,114.0,115.0,116.0,117.0,118.0,119.0,120.0,121.0,122.0,123.0,124.0,125.0,126.0,127.0,128.0,129.0,130.0,131.0,132.0,133.0,134.0,135.0,136.0,137.0,138.0,139.0,140.0,141.0,142.0,143.0,144.0,145.0,146.0,147.0,148.0,149.0,150.0,151.0,152.0,153.0,154.0,155.0,156.0,157.0,158.0,159.0,160.0,161.0,162.0,163.0,164.0,165.0,166.0,167.0,168.0,169.0,170.0,171.0,172.0,173.0,174.0,175.0,176.0,177.0,178.0,179.0,180.0,181.0,182.0,183.0,184.0,185.0,186.0,187.0,188.0,189.0,190.0,191.0,192.0,193.0,194.0,195.0,196.0,197.0,198.0,199.0,200.0,201.0,202.0,203.0,204.0,205.0,206.0,207.0,208.0,209.0,210.0,211.0,212.0,213.0,214.0,215.0,216.0,217.0,218.0,219.0,220.0,221.0,222.0,223.0,224.0,225.0,226.0,227.0,228.0,229.0,230.0,231.0,232.0,233.0,234.0,235.0,236.0,237.0,238.0,239.0,240.0,241.0,242.0,243.0,244.0,245.0,246.0,247.0,248.0,249.0,250.0,251.0,252.0,253.0,254.0,255.0,256.0,257.0,258.0,259.0,260.0,261.0,262.0,263.0,264.0,265.0,266.0,267.0,268.0,269.0,270.0,271.0,272.0,273.0,274.0,275.0,276.0,277.0,278.0,279.0,280.0,281.0,282.0,283.0,284.0,285.0,286.0,287.0,288.0,289.0,290.0,291.0,292.0,293.0,294.0,295.0,296.0,297.0,298.0,299.0,300.0,301.0,302.0,303.0,304.0,305.0,306.0,307.0,308.0,309.0,310.0,311.0,312.0,313.0,314.0,315.0,316.0,317.0,318.0,319.0,320.0,321.0,322.0,323.0,324.0,325.0,326.0,327.0,328.0,329.0,330.0,331.0,332.0,333.0,334.0,335.0,336.0,337.0,338.0,339.0,340.0,341.0,342.0,343.0,344.0,345.0,346.0,347.0,348.0,349.0,350.0,351.0,352.0,353.0,354.0,355.0,356.0,357.0,358.0,359.0,360.0,361.0,362.0,363.0,364.0,365.0,366.0,367.0,368.0,369.0,370.0,371.0,372.0,373.0,374.0,375.0,376.0,377.0,378.0,379.0,380.0,381.0,382.0,383.0,384.0,385.0,386.0,387.0,388.0,389.0,390.0,391.0,392.0,393.0,394.0,395.0,396.0,397.0,398.0,399.0,400.0,401.0,402.0,403.0,404.0,405.0,406.0,407.0,408.0,409.0,410.0,411.0,412.0,413.0,414.0,415.0,416.0,417.0,418.0,419.0,420.0,421.0,422.0,423.0,424.0,425.0,426.0,427.0,428.0,429.0,430.0,431.0,432.0,433.0,434.0,435.0,436.0,437.0,438.0,439.0,440.0,441.0,442.0,443.0,444.0,445.0,446.0,447.0,448.0,449.0,450.0,451.0,452.0,453.0,454.0,455.0,456.0,457.0,458.0,459.0,460.0,461.0,462.0,463.0,464.0,465.0,466.0,467.0,468.0,469.0,470.0,471.0,472.0,473.0,474.0,475.0,476.0,477.0,478.0,479.0,480.0,481.0,482.0,483.0,484.0,485.0,486.0,487.0,488.0,489.0,490.0,491.0,492.0,493.0,494.0,495.0,496.0,497.0,498.0,499.0,500.0,501.0,502.0,503.0,504.0,505.0,506.0,507.0,508.0,509.0,510.0,511.0,512.0,513.0,514.0,515.0,516.0,517.0,518.0,519.0,520.0,521.0,522.0,523.0,524.0,525.0,526.0,527.0,528.0,529.0,530.0,531.0,532.0,533.0,534.0,535.0,536.0,537.0,538.0,539.0,540.0,541.0,542.0,543.0,544.0,545.0,546.0,547.0,548.0,549.0,550.0,551.0,552.0,553.0,554.0,555.0,556.0,557.0,558.0,559.0,560.0,561.0,562.0,563.0,564.0,565.0,566.0,567.0,568.0,569.0,570.0,571.0,572.0,573.0,574.0,575.0,576.0,577.0,578.0,579.0,580.0,581.0,582.0,583.0,584.0,585.0,586.0,587.0,588.0,589.0,590.0,591.0,592.0,593.0,594.0,595.0,596.0,597.0,598.0,599.0,600.0,601.0,602.0,603.0,604.0,605.0,606.0,607.0,608.0,609.0,610.0,611.0,612.0,613.0,614.0,615.0,616.0,617.0,618.0,619.0,620.0,621.0,622.0,623.0,624.0,625.0,626.0,627.0,628.0,629.0,630.0,631.0,632.0,633.0,634.0,635.0,636.0,637.0,638.0,639.0,640.0,641.0,642.0,643.0,644.0,645.0,646.0,647.0,648.0,649.0,650.0,651.0,652.0,653.0,654.0,655.0,656.0,657.0,658.0,659.0,660.0,661.0,662.0,663.0,664.0,665.0,666.0,667.0,668.0,669.0,670.0,671.0,672.0,673.0,674.0,675.0,676.0,677.0,678.0,679.0,680.0,681.0,682.0,683.0,684.0,685.0,686.0,687.0,688.0,689.0,690.0,691.0,692.0,693.0,694.0,695.0,696.0,697.0,698.0,699.0,700.0,701.0,702.0,703.0,704.0,705.0,706.0,707.0,708.0,709.0,710.0,711.0,712.0,713.0,714.0,715.0,716.0,717.0,718.0,719.0,720.0,721.0,722.0,723.0,724.0,725.0,726.0,727.0,728.0,729.0,730.0,731.0,732.0,733.0,734.0,735.0,736.0,737.0,738.0,739.0,740.0,741.0,742.0,743.0,744.0,745.0,746.0,747.0,748.0,749.0,750.0,751.0,752.0,753.0,754.0,755.0,756.0,757.0,758.0,759.0,760.0,761.0,762.0,763.0,764.0,765.0,766.0,767.0,768.0,769.0,770.0,771.0,772.0,773.0,774.0,775.0,776.0,777.0,778.0,779.0,780.0,781.0,782.0,783.0,784.0,785.0,786.0,787.0,788.0,789.0,790.0,791.0,792.0,793.0,794.0,795.0,796.0,797.0,798.0,799.0,800.0,801.0,802.0,803.0,804.0,805.0,806.0,807.0,808.0,809.0,810.0,811.0,812.0,813.0,814.0,815.0,816.0,817.0,818.0,819.0,820.0,821.0,822.0,823.0,824.0,825.0,826.0,827.0,828.0,829.0,830.0,831.0,832.0,833.0,834.0,835.0,836.0,837.0,838.0,839.0,840.0,841.0,842.0,843.0,844.0,845.0,846.0,847.0,848.0,849.0,850.0,851.0,852.0,853.0,854.0,855.0,856.0,857.0,858.0,859.0,860.0,861.0,862.0,863.0,864.0,865.0,866.0,867.0,868.0,869.0,870.0,871.0,872.0,873.0,874.0,875.0,876.0,877.0,878.0,879.0,880.0,881.0,882.0,883.0,884.0,885.0,886.0,887.0,888.0,889.0,890.0,891.0,892.0,893.0,894.0,895.0,896.0,897.0,898.0,899.0,900.0,901.0,902.0,903.0,904.0,905.0,906.0,907.0,908.0,909.0,910.0,911.0,912.0,913.0,914.0,915.0,916.0,917.0,918.0,919.0,920.0,921.0,922.0,923.0,924.0,925.0,926.0,927.0,928.0,929.0,930.0,931.0,932.0,933.0,934.0,935.0,936.0,937.0,938.0,939.0,940.0,941.0,942.0,943.0,944.0,945.0,946.0,947.0,948.0,949.0,950.0,951.0,952.0,953.0,954.0,955.0,956.0,957.0,958.0,959.0,960.0,961.0,962.0,963.0,964.0,965.0,966.0,967.0,968.0,969.0,970.0,971.0,972.0,973.0,974.0,975.0,976.0,977.0,978.0,979.0,980.0,981.0,982.0,983.0,984.0,985.0,986.0,987.0,988.0,989.0,990.0,991.0,992.0,993.0,994.0,995.0,996.0,997.0,998.0,999.0],\"y\":[0.22921014404296874,0.2390748748779297,0.2314827880859375,0.22935078430175782,0.22999317932128907,0.23046263122558594,0.22983702087402344,0.22917596435546875,0.2291354522705078,0.2287362823486328,0.2314126434326172,0.22763241577148438,0.23029054260253906,0.23071031188964844,0.22689480590820313,0.22760183715820312,0.22794735717773437,0.2336214599609375,0.22923182678222656,0.22719538879394532,0.2284053192138672,0.22872947692871093,0.23002349853515625,0.227528076171875,0.22964590454101563,0.22778807067871093,0.228723876953125,0.22728775024414063,0.22762820434570313,0.22779617309570313,0.22970753479003905,0.22541168212890625,0.226739013671875,0.22734255981445312,0.2280202178955078,0.22213055419921876,0.21884132385253907,0.22595318603515624,0.23166441345214844,0.23268399047851562,0.22390086364746092,0.22205520629882813,0.22352214050292968,0.22834988403320314,0.226400390625,0.22761366271972655,0.2265719451904297,0.22740390014648437,0.22583963012695313,0.22788594055175782,0.22222145080566405,0.22250363159179687,0.22157196044921876,0.2210971221923828,0.2237431640625,0.22026597595214845,0.21009463500976563,0.2231237030029297,0.21794131469726563,0.21717703247070314,0.21919815063476564,0.2309578399658203,0.23292420959472657,0.229357421875,0.22525128173828124,0.22801219177246093,0.2272662353515625,0.22302656555175782,0.2244376525878906,0.2262225036621094,0.2215829620361328,0.22047406005859374,0.22427691650390624,0.2180790252685547,0.2235234375,0.22203953552246095,0.22363516235351563,0.22448670959472655,0.22449798583984376,0.21264350891113282,0.21937913513183593,0.21398960876464843,0.22007080078125,0.21708956909179689,0.22365786743164062,0.2128928680419922,0.21706951904296876,0.22301560974121093,0.22347102355957033,0.22057244873046875,0.22289810180664063,0.22236328125,0.22336477661132811,0.223595947265625,0.22249786376953126,0.223861572265625,0.21785679626464843,0.23099461364746093,0.22626951599121095,0.21569459533691407,0.2236493682861328,0.2227794647216797,0.22243060302734374,0.22533578491210937,0.21143553161621093,0.21723068237304688,0.21671890258789062,0.22384547424316406,0.2176463165283203,0.21621807861328124,0.21899722290039061,0.2177839813232422,0.22343031311035155,0.21533792114257813,0.22568576049804687,0.21487800598144532,0.2074937744140625,0.21887277221679688,0.2198909149169922,0.21221820068359376,0.2160832061767578,0.21260069274902343,0.21272819519042968,0.2202455291748047,0.22689178466796875,0.21334761047363282,0.211993408203125,0.21161923217773437,0.220256591796875,0.21137684631347656,0.21413323974609375,0.2040174255371094,0.22410069274902344,0.20403286743164062,0.2257705993652344,0.20679298400878907,0.2068653869628906,0.22179983520507812,0.2149554443359375,0.21247450256347655,0.2109564208984375,0.2144749298095703,0.2037937316894531,0.2035613098144531,0.2218436584472656,0.21231903076171876,0.21664495849609375,0.1940716094970703,0.19080343627929688,0.20269001770019532,0.1926347198486328,0.21296998596191405,0.204806396484375,0.2128848876953125,0.22204203796386718,0.1996756591796875,0.2117940216064453,0.20572761535644532,0.21264569091796875,0.19749264526367188,0.20460562133789062,0.20621601867675782,0.21115997314453125,0.1936519775390625,0.21470260620117188,0.19718048095703125,0.20424038696289062,0.1964798583984375,0.2130302276611328,0.20844070434570314,0.20593484497070313,0.20059666442871094,0.20085322570800782,0.2017504425048828,0.20694189453125,0.195604248046875,0.20073536682128906,0.22190892028808593,0.21546043395996095,0.204661865234375,0.18581004333496093,0.19613990783691407,0.21066142272949218,0.22508486938476563,0.20498126220703125,0.2033245849609375,0.1976033020019531,0.19033474731445313,0.20085166931152343,0.18993927001953126,0.20143983459472656,0.21698539733886718,0.1945299987792969,0.21386749267578126,0.21179632568359374,0.20826823425292967,0.1916340789794922,0.20586212158203124,0.18539396667480468,0.18757212829589845,0.1930655517578125,0.1894355926513672,0.187606689453125,0.21665032958984376,0.21116921997070312,0.2006433410644531,0.19358712768554687,0.19432614135742188,0.1936103057861328,0.20097857666015626,0.20119207763671876,0.19003408813476563,0.2080641326904297,0.20191140747070313,0.2037544403076172,0.18344325256347657,0.19017733764648437,0.21259609985351563,0.2204307403564453,0.19713278198242187,0.20311434936523437,0.18537469482421876,0.18198460388183593,0.2008788299560547,0.20028968811035155,0.19465789794921876,0.20707844543457032,0.20857426452636718,0.19315377807617187,0.1937609405517578,0.19599314880371094,0.2061564025878906,0.2155445556640625,0.1932583770751953,0.22250433349609375,0.19327896118164062,0.1923993682861328,0.21992056274414062,0.18397032165527344,0.19926878356933594,0.19452828979492187,0.19730863952636718,0.19909300231933594,0.19225650024414062,0.20492034912109375,0.18230490112304687,0.21650714111328126,0.197767822265625,0.1890533447265625,0.1954505615234375,0.19552734375,0.18851983642578124,0.20000846862792968,0.19786465454101562,0.1889449920654297,0.19784408569335937,0.22309458923339845,0.2045092010498047,0.18982887268066406,0.20639495849609374,0.18260922241210936,0.20081011962890624,0.20430291748046875,0.19124273681640624,0.19453953552246095,0.1868441619873047,0.20997787475585938,0.2041173095703125,0.18850764465332032,0.2034547576904297,0.20274159240722656,0.21564755249023437,0.20401567077636718,0.1991822052001953,0.19508078002929688,0.1988779296875,0.2096524658203125,0.21082675170898438,0.18494053649902345,0.19956007385253907,0.1946352996826172,0.20360667419433592,0.18158892822265624,0.17727444458007813,0.18690122985839844,0.19793409729003905,0.19727590942382814,0.19147103881835936,0.1960062713623047,0.2003994598388672,0.19195921325683593,0.19311122131347655,0.17723243713378906,0.19558053588867189,0.19367991638183593,0.207018310546875,0.1884307861328125,0.18768869018554687,0.18998590087890624,0.18362428283691407,0.1798906707763672,0.18604173278808595,0.20376161193847656,0.1906973114013672,0.1839107208251953,0.1765325927734375,0.18162313842773437,0.1849342803955078,0.2104998321533203,0.18678866577148437,0.18993992614746094,0.1811300811767578,0.19326628112792968,0.18985879516601561,0.1878066864013672,0.18587237548828126,0.2021844787597656,0.1841910858154297,0.19105914306640626,0.18505303955078126,0.19540008544921875,0.18533930969238283,0.1673363037109375,0.19274497985839845,0.19025895690917968,0.17986428833007811,0.18154469299316406,0.185156005859375,0.17313438415527344,0.19988253784179688,0.20151220703125,0.19512969970703126,0.19363713073730468,0.19755899047851563,0.18283071899414063,0.1844021301269531,0.18937850952148438,0.18977510070800782,0.1745948944091797,0.2044425048828125,0.18701106262207032,0.19484445190429686,0.19570736694335938,0.18101596069335937,0.19406295776367188,0.17896107482910156,0.18487930297851562,0.19788084411621093,0.20212178039550782,0.196089599609375,0.18868560791015626,0.18137937927246095,0.20069911193847656,0.17378178405761718,0.19475875854492186,0.18167518615722655,0.19010150146484375,0.17725999450683594,0.19811932373046875,0.19676150512695312,0.1795958251953125,0.18194744873046875,0.19293392944335938,0.19509906005859376,0.18465631103515626,0.177396240234375,0.19203883361816407,0.19064068603515624,0.19525392150878906,0.19080596923828125,0.20949903869628905,0.20497894287109375,0.17980790710449218,0.19368161010742188,0.1891999206542969,0.18543626403808594,0.1813992156982422,0.18868618774414062,0.19999409484863281,0.18202932739257813,0.19680223083496093,0.20847389221191406,0.184623046875,0.20153512573242188,0.19764897155761718,0.17898373413085938,0.18404144287109375,0.1898447265625,0.17959306335449218,0.17884385681152343,0.18569949340820313,0.17378025817871093,0.16946345520019532,0.1756348571777344,0.1911221160888672,0.20369503784179688,0.18394427490234375,0.18687582397460936,0.18882669067382812,0.19365792846679689,0.17755577087402344,0.20013070678710937,0.1974019012451172,0.19735096740722657,0.1833412628173828,0.20173233032226562,0.1822537078857422,0.18085179138183594,0.1828844757080078,0.17558018493652344,0.17631607055664061,0.20172163391113282,0.18330137634277344,0.17285684204101562,0.19244546508789062,0.1933973083496094,0.1907450714111328,0.19444017028808594,0.18163339233398437,0.17835693359375,0.16660403442382812,0.17093501281738283,0.1827201690673828,0.19953607177734375,0.18970562744140626,0.19061570739746095,0.19215440368652345,0.1835625,0.19664593505859376,0.1887874298095703,0.18415522766113282,0.18202995300292968,0.19378077697753907,0.18261595153808594,0.18837962341308595,0.1960694122314453,0.1833814239501953,0.20046308898925783,0.17054779052734376,0.18280313110351562,0.17939096069335939,0.17679046630859374,0.20512046813964843,0.17444554138183593,0.16851039123535155,0.17276708984375,0.17745834350585937,0.178263916015625,0.20383447265625,0.18134884643554688,0.18040457153320313,0.19398529052734376,0.16166766357421875,0.1836324005126953,0.18852613830566406,0.1815432891845703,0.18060067749023437,0.18658758544921875,0.17128823852539063,0.18129718017578125,0.1650917510986328,0.17710137939453124,0.1854451904296875,0.18607011413574218,0.21067724609375,0.1912703857421875,0.18970297241210937,0.18118133544921874,0.183083984375,0.1860835418701172,0.17021797180175782,0.19292657470703126,0.1843902587890625,0.1842202911376953,0.18596525573730469,0.19266740417480469,0.193453125,0.20962057495117187,0.19494744873046874,0.18641641235351564,0.1844250946044922,0.19243344116210936,0.19683619689941406,0.18232083129882812,0.1679581298828125,0.2051273956298828,0.17630812072753907,0.19823362731933594,0.17745504760742187,0.170973876953125,0.1919202880859375,0.17900698852539063,0.20305389404296875,0.17595057678222656,0.18253324890136718,0.17034054565429688,0.1622201385498047,0.18732015991210937,0.17235044860839843,0.19253031921386718,0.18952481079101563,0.1923919677734375,0.19897703552246093,0.17265277099609375,0.17702566528320313,0.16937777709960938,0.1872617645263672,0.17607521057128905,0.18285986328125,0.1712176055908203,0.16146342468261718,0.19712225341796874,0.19102580261230467,0.20726744079589843,0.17745751953125,0.19504316711425781,0.17387449645996095,0.1770536346435547,0.18119558715820314,0.18072215270996095,0.1933500518798828,0.16022605895996095,0.17294497680664062,0.18978280639648437,0.19350408935546876,0.1872000732421875,0.19186473083496094,0.18303129577636718,0.1790877685546875,0.17654983520507814,0.17868687438964845,0.18902299499511718,0.1712955780029297,0.18981051635742188,0.16447042846679688,0.1705194549560547,0.1915639343261719,0.17343971252441406,0.18531130981445312,0.16871791076660156,0.1849086151123047,0.17834187316894531,0.18562174987792968,0.2007291259765625,0.17488211059570313,0.17228504943847656,0.1913366241455078,0.17290299987792968,0.18523341369628907,0.17736318969726564,0.18489059448242187,0.17323789978027343,0.17588612365722656,0.18236651611328125,0.17609403991699218,0.19631636047363282,0.1836826477050781,0.17625834655761718,0.1827941436767578,0.1932236785888672,0.15617007446289063,0.18254306030273437,0.17802626037597657,0.1958035888671875,0.175273193359375,0.1991144256591797,0.1766771697998047,0.21237396240234374,0.17396221923828126,0.17272476196289063,0.16988429260253907,0.1758140411376953,0.1636127471923828,0.1814197998046875,0.17829757690429687,0.16829225158691405,0.18361787414550781,0.18285020446777345,0.17412532043457032,0.1734700469970703,0.19027763366699219,0.17612704467773438,0.17709217834472657,0.1911383361816406,0.17697439575195312,0.18606271362304688,0.17201960754394532,0.1806478271484375,0.16758584594726564,0.1734156494140625,0.17377996826171874,0.18403373718261717,0.157393798828125,0.18656163024902345,0.17168461608886718,0.16015438842773438,0.17705593872070313,0.17546194458007813,0.19666166687011719,0.19372866821289061,0.20241465759277344,0.18780253601074218,0.20228182983398438,0.1569820556640625,0.19347880554199218,0.1937175750732422,0.1763279571533203,0.17736288452148438,0.17073727416992188,0.17472366333007813,0.18684725952148437,0.18746253967285156,0.18218119812011718,0.15741946411132812,0.19381185913085938,0.1715307159423828,0.18563267517089843,0.16442486572265624,0.17542935180664063,0.16516444396972657,0.17718821716308594,0.16465379333496094,0.19404098510742188,0.1690161590576172,0.171694091796875,0.16940280151367187,0.19124417114257813,0.17935330200195312,0.16211016845703125,0.17658348083496095,0.17140582275390626,0.17831410217285157,0.17754531860351563,0.17060789489746095,0.1674521026611328,0.18055845642089843,0.18039891052246093,0.16827110290527345,0.17868006896972657,0.16520655822753907,0.17536257934570312,0.17121266174316407,0.21015493774414062,0.178514892578125,0.1616918182373047,0.17201422119140625,0.17307722473144532,0.1908151092529297,0.17984629821777343,0.1894293212890625,0.17730621337890626,0.18878694152832032,0.14971937561035156,0.1713649139404297,0.1843951416015625,0.16639283752441406,0.17834220886230467,0.16779472351074218,0.18201536560058593,0.1584030456542969,0.19029389953613282,0.1665952911376953,0.17789651489257813,0.17360357666015624,0.1718477325439453,0.17981109619140626,0.16322972106933595,0.17115573120117186,0.15628065490722656,0.18482441711425782,0.16363238525390625,0.18492233276367187,0.15060801696777343,0.18202352905273436,0.1702250213623047,0.18630833435058594,0.16613427734375,0.17933790588378906,0.19843460083007813,0.1916425018310547,0.18604815673828126,0.1680279541015625,0.16453091430664063,0.17654891967773437,0.17394960021972655,0.163294677734375,0.15628182983398436,0.18063275146484375,0.1824931640625,0.1714193878173828,0.16270773315429687,0.17135362243652344,0.17198980712890624,0.17831951904296875,0.16979052734375,0.18365179443359375,0.18725823974609376,0.18571804809570314,0.16558741760253906,0.17013522338867187,0.18409246826171874,0.16937153625488283,0.1771487579345703,0.17327133178710938,0.16443727111816406,0.1668148651123047,0.17755126953125,0.1874080352783203,0.16868290710449219,0.16022695922851563,0.1657538604736328,0.17159226989746093,0.16787954711914063,0.17322296142578125,0.1853270263671875,0.16612803649902344,0.18319544982910158,0.16535292053222655,0.17121527099609374,0.16768751525878905,0.17362330627441405,0.1737310485839844,0.1806397399902344,0.15470169067382813,0.17959170532226562,0.19066355895996093,0.16558932495117187,0.15776776123046876,0.17684866333007812,0.1654068298339844,0.17762149047851564,0.19484429931640626,0.18778335571289062,0.16633229064941407,0.19335818481445313,0.17103857421875,0.19690231323242188,0.15721197509765625,0.20391688537597658,0.16474894714355467,0.16805789184570313,0.20535809326171875,0.17926119995117187,0.16820196533203124,0.1838050994873047,0.1995489501953125,0.1618080291748047,0.18013606262207033,0.15760226440429687,0.1754873809814453,0.18337278747558594,0.1849562530517578,0.18656619262695312,0.1836622314453125,0.19850888061523436,0.17699522399902343,0.18676194763183593,0.17590545654296874,0.16412806701660157,0.17852738952636718,0.1699628143310547,0.16199713134765625,0.15041314697265626,0.16133955383300783,0.18373313903808594,0.19175321960449218,0.168410888671875,0.17740902709960937,0.17011795043945313,0.17260015869140624,0.1712694549560547,0.18816600036621095,0.18268411254882813,0.165120849609375,0.17496966552734375,0.17322036743164063,0.1358838653564453,0.1653114013671875,0.15663287353515626,0.17677206420898436,0.16732308959960937,0.16793026733398436,0.17361253356933593,0.1743499755859375,0.15116493225097657,0.15002565002441406,0.15426324462890625,0.14814749145507813,0.16285731506347656,0.1603948211669922,0.17824813842773438,0.17343804931640625,0.15877008056640626,0.17262615966796874,0.16995452880859374,0.20231684875488282,0.17733883666992187,0.1519136962890625,0.17121943664550782,0.15894894409179688,0.17003208923339844,0.17607632446289062,0.16977919006347655,0.16763595581054688,0.16493759155273438,0.1825316619873047,0.16904144287109374,0.15615785217285155,0.17517471313476562,0.16654324340820312,0.17084011840820312,0.16771653747558593,0.17545701599121094,0.1842067565917969,0.15739451599121093,0.17352752685546874,0.17149160766601562,0.18471170043945312,0.16633064270019532,0.18789776611328124,0.16240646362304687,0.18026124572753907,0.16351376342773438,0.16750460815429688,0.15693670654296876,0.177343017578125,0.1466272277832031,0.16779908752441405,0.16868489074707033,0.16028155517578124,0.14621897888183594,0.1891246795654297,0.19164292907714844,0.17810382080078124,0.17798931884765626,0.169196044921875,0.1604300537109375,0.1671268615722656,0.15671664428710938,0.18388410949707032,0.1700780487060547,0.16785531616210939,0.16579899597167969,0.17729273986816407,0.17276126098632813,0.1499797821044922,0.15699681091308593,0.18925141906738283,0.16977783203125,0.17644038391113281,0.1548943634033203,0.1723308563232422,0.17372145080566406,0.1704222869873047,0.17401919555664064,0.17063929748535156,0.17375965881347658,0.1780141296386719,0.1591208038330078,0.16591464233398437,0.16390402221679687,0.16471652221679686,0.167620361328125,0.16665371704101561,0.16414126586914063,0.1631876525878906,0.1553340606689453,0.1680596923828125,0.14250497436523438,0.173476806640625,0.18428358459472657,0.1763408203125,0.15680470275878905,0.15780300903320313,0.1569093780517578,0.17248880004882813,0.1723570098876953,0.15365802001953124,0.13810482788085937,0.1661783447265625,0.17595217895507811,0.1699673156738281,0.16027584838867187,0.19771022033691407,0.16507951354980469,0.17268313598632812,0.17163970947265625,0.15631278991699218,0.1763902587890625,0.1781455535888672,0.15492437744140625,0.16198455810546875,0.1750988311767578,0.1792062225341797,0.1559850311279297,0.15791261291503905,0.1730289306640625,0.18338810729980468,0.1573764190673828,0.17204998779296876,0.17537091064453125,0.152889892578125,0.17301332092285157,0.14731364440917968,0.17267247009277345,0.17131402587890626,0.153628662109375,0.17630526733398438,0.16300247192382813,0.19187705993652343,0.17187669372558595,0.1754461669921875,0.1861351776123047,0.16342901611328126,0.14448782348632813,0.1756241912841797,0.16801885986328124,0.17183265686035157,0.1664890594482422,0.16032208251953126,0.17384735107421875,0.1480910186767578,0.14979583740234376,0.17842387390136719,0.1615977020263672,0.1496914520263672,0.19158343505859374,0.17528883361816405,0.17855836486816407,0.17001475524902343,0.16113136291503907,0.17389207458496095,0.16991287231445312,0.15709136962890624,0.15530638122558593,0.14951930236816408,0.16686557006835936,0.13795094299316407,0.15026980590820313,0.1595890197753906,0.16691461181640624,0.16966485595703126,0.14356353759765625,0.16028773498535157,0.15587094116210937,0.18254266357421875,0.17906022644042968,0.18227162170410155,0.15040428161621094,0.17047016906738283,0.14025408935546874,0.1636669158935547,0.16735183715820312,0.15166246032714845,0.18969081115722655,0.15950230407714844,0.1556898956298828,0.16487179565429688,0.14989022827148438,0.16619407653808593,0.16449542236328124,0.14662538146972656,0.18801274108886717,0.18157852172851563,0.18169630432128905,0.14901132202148437,0.1598625030517578,0.16050457763671874,0.17044873046875,0.17442384338378905,0.19029313659667968,0.15803738403320314,0.16634596252441405,0.163609375,0.1567806396484375,0.1694370880126953,0.18244544982910157,0.17217509460449218,0.15775784301757811,0.16479771423339845,0.1435131378173828,0.14776856994628906,0.15806413269042968,0.17620201110839845,0.165968994140625,0.17042341613769532,0.17985263061523438,0.13676934814453126,0.15966741943359375,0.1850160675048828,0.1651248779296875,0.15496597290039063,0.16593280029296875,0.15183322143554687,0.16519041442871094,0.15013142395019533,0.16937490844726563,0.1621957550048828,0.18097335815429688,0.1495586395263672]};\n",
       "\n",
       "  var data = [data0];\n",
       "  var layout = {\"title\":\"loss by time\"};\n",
       "\n",
       "  Plotly.plot('plot-1746384081', data, layout);\n",
       "})();\n",
       "});\n",
       "      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "trainer.plotLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Serialization\n",
    "// writeWeightsAndBias(version = currentVersion, model = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict  your Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the processed test data to verify the prediction result of the neural network and compute the accuracy. The accuracy shall be about 32%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// val predictResult = Await.result(myNeuralNetwork(testData).predict.toScalaFuture, Duration.Inf)\n",
    "\n",
    "// myNeuralNetwork\n",
    "\n",
    "def getAccuracyResult(): String = {\n",
    "    def findMaxItemIndex(iNDArray: INDArray): INDArray = {\n",
    "        Nd4j.argMax(iNDArray, 1)\n",
    "    }\n",
    "    \n",
    "    def getAccuracy(score: INDArray, testExpectLabel: INDArray): Double = {\n",
    "        import org.nd4s.Implicits._\n",
    "        val scoreIndex = findMaxItemIndex(score)\n",
    "        val expectResultIndex = findMaxItemIndex(testExpectLabel)\n",
    "        val accINDArray = scoreIndex.eq(expectResultIndex)\n",
    "        (accINDArray.sumT / score.shape()(0))\n",
    "    }\n",
    "    \n",
    "    \n",
    "    val accuracyResultBuffer = scala.collection.mutable.Buffer.empty[Double]\n",
    "    val iterator = cifar10.testBatches(trainBatchSize)\n",
    "    while (iterator.hasNext) {\n",
    "        val Cifar10.Batch(testDatalabels, testDataBatch) = iterator.next()\n",
    "        val predictResult = Await.result(myNeuralNetwork(testDataBatch).predict.toScalaFuture, Duration.Inf)\n",
    "        val accuracyResult = getAccuracy(predictResult ,testDatalabels)\n",
    "        accuracyResultBuffer += accuracyResult\n",
    "    }\n",
    "\n",
    "    val accuracy = accuracyResultBuffer.sum / accuracyResultBuffer.length\n",
    "    \n",
    "    s\"${accuracy * 100.0}%\"\n",
    "}\n",
    "\n",
    "\n",
    "println(s\"The accuracy is ${getAccuracyResult()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We have learned the follows in this article:\n",
    "\n",
    "* Prepare and process CIFAR10 data\n",
    "* Write softmax classifier\n",
    "* Use the prediction image of the neural network written by softmax classifier to match with the probability of each category."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
