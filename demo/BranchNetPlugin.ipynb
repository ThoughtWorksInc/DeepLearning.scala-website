{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$plugin.$                                          \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$plugin.$                                            \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                      \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $plugin.$ivy.`org.spire-math::kind-projector:0.9.4`\n",
    "import $plugin.$ivy.`org.scalamacros:paradise_2.11.11:2.1.0`\n",
    "import $ivy.`com.thoughtworks.deeplearning::plugins-builtins:2.0.0`\n",
    "import $ivy.`com.thoughtworks.each::each:3.3.1`\n",
    "import $ivy.`org.nd4j:nd4j-native-platform:0.8.0`\n",
    "import $ivy.`org.rauschig:jarchivelib:0.5.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.concurrent.ExecutionContext.Implicits.global\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.nd4j.linalg.api.ndarray.INDArray\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.nd4j.linalg.convolution.Convolution\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.nd4j.linalg.util.ArrayUtil\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.nd4j.linalg.factory.Nd4j\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.nd4j.linalg.api.ops.impl.transforms.IsMax\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscalaz.syntax.all._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscalaz.std.anyVal._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.future._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.raii.shared._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.raii.asynchronous._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.feature.ImplicitApply\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.each.Monadic._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.feature.Factory\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.DeepLearning\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.DeepLearning.Tape\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.INDArrayWeights\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.INDArrayLayers\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.Operators\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.Training\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.Builtins\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.ImplicitsSingleton\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.concurrent.ExecutionContext.Implicits.global\n",
    "import org.nd4j.linalg.api.ndarray.INDArray\n",
    "import org.nd4j.linalg.convolution.Convolution\n",
    "import org.nd4j.linalg.util.ArrayUtil\n",
    "import org.nd4j.linalg.factory.Nd4j\n",
    "import org.nd4j.linalg.api.ops.impl.transforms.IsMax\n",
    "import scalaz.syntax.all._\n",
    "import scalaz.std.anyVal._\n",
    "import com.thoughtworks.future._\n",
    "import com.thoughtworks.raii.shared._\n",
    "import com.thoughtworks.raii.asynchronous._\n",
    "import com.thoughtworks.feature.ImplicitApply\n",
    "import com.thoughtworks.each.Monadic._\n",
    "import com.thoughtworks.feature.Factory\n",
    "import com.thoughtworks.deeplearning.DeepLearning\n",
    "import com.thoughtworks.deeplearning.DeepLearning.Tape\n",
    "import com.thoughtworks.deeplearning.plugins.INDArrayWeights\n",
    "import com.thoughtworks.deeplearning.plugins.INDArrayLayers\n",
    "import com.thoughtworks.deeplearning.plugins.Operators\n",
    "import com.thoughtworks.deeplearning.plugins.Training\n",
    "import com.thoughtworks.deeplearning.plugins.Builtins\n",
    "import com.thoughtworks.deeplearning.plugins.ImplicitsSingleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load(scala.io.Source.fromURL(new java.net.URL(\"https://gist.githubusercontent.com/TerrorJack/cdd9cc5adc82fc86abf8b4c72cd26e76/raw/1f15523ee4b5a7fcc7e7317ae34ba09be207a62a/CNN.sc\")).mkString)\n",
    "\n",
    "interp.load(scala.io.Source.fromURL(new java.net.URL(\"https://gist.github.com/Atry/1fb0608c655e3233e68b27ba99515f16/raw/39ba06ee597839d618f2fcfe9526744c60f2f70a/FixedLearningRate.sc\")).mkString)\n",
    "\n",
    "interp.load(scala.io.Source.fromURL(new java.net.URL(\"https://gist.github.com/Atry/89ee1baa4c161b8ccc1b82cdd9c109fe/raw/d39cec0483a78a514342b16567aebebe0f890d38/Adagrad.sc\")).mkString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mNumberOfFilters\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m128\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NumberOfFilters = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.net.URI\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file._\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mtrait\u001b[39m \u001b[36mBranchNet\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.io._\n",
    "import java.net.URI\n",
    "import java.nio.file._\n",
    "\n",
    "trait BranchNet extends CNNs with Builtins with Adagrad {\n",
    "    val fileHandler = new java.util.logging.FileHandler(s\"BranchNet-${management.ManagementFactory.getRuntimeMXBean.getName}-%g.log\")\n",
    "    logger.addHandler(fileHandler)\n",
    "\n",
    "    final case class WeightFile(weight: INDArrayWeight, relativePath: Path) {\n",
    "        def backup(parent: Path): Unit = {\n",
    "            val resolvedPath = parent.resolve(relativePath)\n",
    "            Files.createDirectories(resolvedPath.getParent)\n",
    "            val stream = new ObjectOutputStream(new BufferedOutputStream(Files.newOutputStream(resolvedPath, StandardOpenOption.CREATE_NEW)))\n",
    "            try {\n",
    "                stream.writeObject(weight.data)\n",
    "                stream.writeObject(weight.cache)\n",
    "            } finally {\n",
    "                stream.close()\n",
    "            }\n",
    "        } \n",
    "    }\n",
    "\n",
    "    trait ImplicitsApi extends super[CNNs].ImplicitsApi with super[Builtins].ImplicitsApi\n",
    "    type Implicits <: ImplicitsApi\n",
    "    \n",
    "    import implicits._\n",
    "\n",
    "    def softmax[Out <: INDArrayLayer](scores: INDArrayLayer)(implicit layerImplicits: ImplicitApply.Aux[indArrayPartialApplyRawForward.Rest, Out]): Out = {\n",
    "        val expScores = exp(scores)\n",
    "        expScores / expScores.sum(1)\n",
    "    }\n",
    "\n",
    "    final class Model[Out](parent: Path,\n",
    "                numberOfCoarseClasses: Int,\n",
    "                numberOfFineClassesPerCoarseClass: Int,\n",
    "                kernelSize: Int = 3, //F 卷积核的空间尺寸\n",
    "                padding: Int = 1, //零填充数量\n",
    "                stride: Int = 1 // 步长l\n",
    "    )(implicit val implicitApplyRest: ImplicitApply.Aux[indArrayPartialApplyData.Rest, Out],\n",
    "      asINDArrayWeight: Out <:< INDArrayWeight) {\n",
    "        var version = {\n",
    "            val versionFile = parent.resolve(\"version\")\n",
    "            if (Files.exists(versionFile)) {\n",
    "                new String(Files.readAllBytes(versionFile), scala.io.Codec.UTF8.charSet).toInt\n",
    "            } else {\n",
    "                Files.createDirectories(parent)\n",
    "                Files.write(versionFile, \"0\".getBytes(\"UTF-8\"))\n",
    "                0\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "        def loadOrInitialize[Out <: INDArrayWeight](\n",
    "                relativePath: Path,\n",
    "                initialValue: () => INDArray): WeightFile = {\n",
    "            val versionedPath = parent.resolve(version.toString)\n",
    "            val resolvedPath = versionedPath.resolve(relativePath)\n",
    "            if (Files.exists(resolvedPath)) {\n",
    "                logger.info(s\"Loading weight from $resolvedPath...\")\n",
    "                val stream = new ObjectInputStream(new BufferedInputStream(Files.newInputStream(resolvedPath)))\n",
    "                try {\n",
    "                    val data = stream.readObject().asInstanceOf[INDArray]\n",
    "                    val cache = stream.readObject().asInstanceOf[Option[INDArray]]\n",
    "                    val weight: implicitApplyRest.Out = INDArrayWeight(data)\n",
    "                    // TODO\n",
    "                    // weight.cache = cache\n",
    "                    WeightFile(weight, relativePath)\n",
    "                } finally {\n",
    "                    stream.close()\n",
    "                }\n",
    "            } else {\n",
    "                logger.info(s\"Initialize weight for $resolvedPath...\")\n",
    "                val weightFile = WeightFile(INDArrayWeight(initialValue()), relativePath)\n",
    "                weightFile.backup(versionedPath)\n",
    "                weightFile\n",
    "            }\n",
    "        }\n",
    "\n",
    "        def convolutionThenRelu[Input, Weight, Bias, Out <: INDArrayLayer](\n",
    "                input: Input,\n",
    "                weight: Weight,\n",
    "                bias: Bias)(\n",
    "                 implicit inputDeepLearning: DeepLearning.Aux[Input, INDArray, INDArray],\n",
    "                 weightDeepLearning: DeepLearning.Aux[Weight, INDArray, INDArray],\n",
    "                 biasDeepLearning: DeepLearning.Aux[Bias, INDArray, INDArray],\n",
    "                 layerImplicits: ImplicitApply.Aux[indArrayPartialApplyRawForward.Rest, Out]): Out = {\n",
    "            max(conv2d(input, weight, bias, (kernelSize, kernelSize), (stride, stride), (padding, padding)), 0.0)\n",
    "        }\n",
    "\n",
    "    \n",
    "        private def initialWeightAndBias(path: Path, outputDepth: Int, inputDepth: Int): (WeightFile, WeightFile) = {\n",
    "            import org.nd4s.Implicits._\n",
    "            val weight = loadOrInitialize(\n",
    "                path.resolve(\"weight\"),\n",
    "                { () => \n",
    "                    Nd4j.randn(Array(outputDepth, inputDepth, kernelSize, kernelSize)) *\n",
    "                    math.sqrt(2.0 / inputDepth / kernelSize / kernelSize)\n",
    "                }\n",
    "            )\n",
    "\n",
    "            //When using RELUs, make sure biases are initialised with small *positive* values for example 0.1\n",
    "            val bias = loadOrInitialize(\n",
    "                path.resolve(\"bias\"),                          \n",
    "                () => Nd4j.ones(outputDepth) * 0.0001\n",
    "            )\n",
    "\n",
    "            (weight, bias)\n",
    "        }\n",
    "\n",
    "        def backup(): Unit = {\n",
    "            val currentVersion = synchronized {\n",
    "                version += 1\n",
    "                version\n",
    "            }\n",
    "            val versionFile = parent.resolve(\"version\")\n",
    "            Files.write(versionFile, currentVersion.toString.getBytes(\"UTF-8\"))\n",
    "            val versionedPath = parent.resolve(version.toString)\n",
    "            logger.info(s\"Backing up model to $versionedPath\")\n",
    "            for ((weight, bias) <- coarseNetWeightAndBias) {\n",
    "                weight.backup(versionedPath)\n",
    "                bias.backup(versionedPath)\n",
    "            }\n",
    "            inputWeightAndBias._1.backup(versionedPath)\n",
    "            inputWeightAndBias._2.backup(versionedPath)\n",
    "            for ((weight, bias) <- coarseStage2WeightAndBias) {\n",
    "                weight.backup(versionedPath)\n",
    "                bias.backup(versionedPath)\n",
    "            }\n",
    "            coarseBias.backup(versionedPath)\n",
    "            coarseWeight.backup(versionedPath)\n",
    "            for (subnet <- fineNetWeightAndBiases) {\n",
    "                for ((weight, bias) <- subnet) {\n",
    "                    weight.backup(versionedPath)\n",
    "                    bias.backup(versionedPath)\n",
    "                }\n",
    "            }\n",
    "            for (bias <- fineBiases) {\n",
    "                bias.backup(versionedPath)\n",
    "            }\n",
    "            for (weight <- fineWeights) {\n",
    "                weight.backup(versionedPath)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        val inputWeightAndBias = initialWeightAndBias(Paths.get(\"coarse\", \"cnn\" , \"0\"), NumberOfFilters, 3)\n",
    "        \n",
    "        val coarseNetWeightAndBias = {\n",
    "            for (i <- 1 until 10) yield {\n",
    "                initialWeightAndBias(Paths.get(\"coarse\", \"cnn\", i.toString), NumberOfFilters, NumberOfFilters)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        val coarseStage2WeightAndBias = {\n",
    "            for (i <- 0 until 5) yield {\n",
    "                initialWeightAndBias(Paths.get(\"coarse\", \"cnn_stage2\", i.toString), NumberOfFilters, NumberOfFilters)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        val coarseBias = loadOrInitialize(\n",
    "            Paths.get(\"coarse\", \"fc\", \"bias\"),\n",
    "            () => Nd4j.zeros(numberOfCoarseClasses)\n",
    "        )\n",
    "\n",
    "        val coarseWeight = loadOrInitialize(\n",
    "            Paths.get(\"coarse\", \"fc\", \"weight\"),\n",
    "            { () =>\n",
    "                import org.nd4s.Implicits._\n",
    "                Nd4j.randn(NumberOfFilters * 16 * 16, numberOfCoarseClasses) / math.sqrt(NumberOfFilters * 16 * 16)\n",
    "            }\n",
    "        )\n",
    "\n",
    "        val fineNetWeightAndBiases = for (i <- 0 until numberOfCoarseClasses) yield {\n",
    "            for (j <- 0 until 5) yield {\n",
    "                initialWeightAndBias(Paths.get(\"fine\", i.toString, \"cnn\", j.toString), NumberOfFilters, NumberOfFilters)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        val fineBiases = for (i <- 0 until numberOfCoarseClasses) yield {\n",
    "            loadOrInitialize(\n",
    "                Paths.get(\"fine\", i.toString, \"fc\", \"bias\"),\n",
    "                { () =>\n",
    "                    Nd4j.zeros(numberOfFineClassesPerCoarseClass)\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "\n",
    "        val fineWeights = {\n",
    "            import org.nd4s.Implicits._\n",
    "            for (i <- 0 until numberOfCoarseClasses) yield {\n",
    "                loadOrInitialize(\n",
    "                    Paths.get(\"fine\", i.toString, \"fc\", \"weight\"),\n",
    "                    { () =>\n",
    "                        Nd4j.randn(NumberOfFilters * 16 * 16, numberOfFineClassesPerCoarseClass) / math.sqrt(NumberOfFilters * 16 * 16 / 2)\n",
    "                    }\n",
    "                )\n",
    "            }\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interp.load(\"\"\"\n",
    "    val hyperparameters = Factory[BranchNet with Adagrad with FixedLearningRate with CNNs].newInstance(\n",
    "        learningRate = 0.00001,\n",
    "        eps = 1e-8\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.INDArrayWeight\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.DoubleLayer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.INDArrayLayer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.softmax\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.log\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.implicits._\u001b[39m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyperparameters.INDArrayWeight\n",
    "import hyperparameters.DoubleLayer\n",
    "import hyperparameters.INDArrayLayer\n",
    "import hyperparameters.softmax\n",
    "import hyperparameters.log\n",
    "import hyperparameters.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.etl.Cifar100\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mcifar100\u001b[39m: \u001b[32mcom\u001b[39m.\u001b[32mthoughtworks\u001b[39m.\u001b[32mdeeplearning\u001b[39m.\u001b[32metl\u001b[39m.\u001b[32mCifar100\u001b[39m = \u001b[33mCifar100\u001b[39m(\n",
       "  java.nio.DirectByteBufferR[pos=0 lim=153700000 cap=153700000],\n",
       "  java.nio.DirectByteBufferR[pos=0 lim=30740000 cap=30740000]\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.thoughtworks.deeplearning.etl::cifar100:0.1`\n",
    "\n",
    "import com.thoughtworks.deeplearning.etl.Cifar100\n",
    "\n",
    "val cifar100 = Cifar100.load().blockingAwait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mobject\u001b[39m \u001b[36mModels\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object Models {\n",
    "    val model = new hyperparameters.Model(\n",
    "        Paths.get(\"backup\"),\n",
    "        Cifar100.NumberOfCoarseClasses,\n",
    "        Cifar100.NumberOfFineClassesPerCoarseClass,\n",
    "        3,\n",
    "        1,\n",
    "        1\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mModels.model._\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Models.model._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcoarseStage2Layers\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def coarseStage2Layers(features: INDArrayLayer): INDArrayLayer = {\n",
    "    coarseStage2WeightAndBias.foldLeft(features) { (input, weightFile) =>\n",
    "        convolutionThenRelu(input, weightFile._1.weight, weightFile._2.weight)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcoarseSubNet\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def coarseSubNet(images: INDArray): INDArrayLayer = {\n",
    "    coarseNetWeightAndBias.foldLeft(convolutionThenRelu(images, inputWeightAndBias._1.weight, inputWeightAndBias._2.weight)) { (accumulator, weightAndBias) =>\n",
    "        convolutionThenRelu(accumulator, weightAndBias._1.weight, weightAndBias._2.weight)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mfineSubNet\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fineSubNet(coarseClass: Int, features: INDArrayLayer): INDArrayLayer = {\n",
    "    val output = fineNetWeightAndBiases(coarseClass).foldLeft(features) { (input, weightAndBias) =>\n",
    "        convolutionThenRelu(input, weightAndBias._1.weight, weightAndBias._2.weight)\n",
    "    }\n",
    "    val poolSize = (2, 2)\n",
    "    hyperparameters.maxPool(output, poolSize)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mfullyConnectedLayer\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fullyConnectedLayer(input: INDArrayLayer,\n",
    "                        weight: INDArrayWeight,\n",
    "                        bias: INDArrayWeight,\n",
    "                        imageCount: Int,\n",
    "                        pixelsOfPreLayer: Int): INDArrayLayer = {\n",
    "    input.reshape(imageCount, pixelsOfPreLayer) dot weight + bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcoarseMaxPoolThenFC\u001b[39m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def coarseMaxPoolThenFC(features: INDArrayLayer, imageCount: Int): INDArrayLayer = {\n",
    "    // N * NumberOfFilters * 16 * 16\n",
    "    val layer0 = hyperparameters.maxPool(features, (2, 2))\n",
    "    // N * 20\n",
    "    fullyConnectedLayer(layer0, coarseWeight.weight, coarseBias.weight, imageCount, NumberOfFilters * 16 * 16)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mlossFunction\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lossFunction(probabilities: INDArrayLayer, expectedLabel: INDArray): DoubleLayer = {\n",
    "    -(hyperparameters.log(probabilities + 0.0001) * expectedLabel).mean\n",
    "//     -(log(possibility * 0.9 + 0.1) * expectedLabel + (1.0 - expectedLabel) * log(1.0 - possibility * 0.9)).mean\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mfineFCThenSoftmax\u001b[39m"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fineFCThenSoftmax(features: INDArrayLayer,\n",
    "                      coarseClass: Int,\n",
    "                      imageCount: Int,\n",
    "                      pixelsOfPreLayer: Int): INDArrayLayer = {\n",
    "    val layer0 = fullyConnectedLayer(features, fineWeights(coarseClass).weight, fineBiases(coarseClass).weight, imageCount, pixelsOfPreLayer)\n",
    "    softmax(layer0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mCoarseAccuracyRate\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mFineAccuracyRate\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mAccuracyRate\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mLoss\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type CoarseAccuracyRate = Double\n",
    "type FineAccuracyRate = Double\n",
    "type AccuracyRate = Double\n",
    "type Loss = Double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36maccuracyRate\u001b[39m"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracyRate(coarsePossibility: INDArray,\n",
    "                 finePossibility: INDArray,\n",
    "                 coarseClass: Int,\n",
    "                 fineClasses: INDArray,\n",
    "                 imageCount: Int): (CoarseAccuracyRate, FineAccuracyRate, AccuracyRate) = {\n",
    "    import org.nd4s.Implicits._\n",
    "\n",
    "    // Some assertion to make sure the shape is expected.\n",
    "    val Array(`imageCount`, Cifar100.NumberOfCoarseClasses) = coarsePossibility.shape()\n",
    "    val Array(`imageCount`, Cifar100.NumberOfFineClassesPerCoarseClass) = finePossibility.shape()\n",
    "    val Array(`imageCount`, Cifar100.NumberOfFineClassesPerCoarseClass) = fineClasses.shape()\n",
    "\n",
    "    val isCoarseClassCorrect = Nd4j.argMax(coarsePossibility, 1) eq coarseClass\n",
    "    val isFineClassCorrect = (Nd4j.argMax(finePossibility, 1) eq Nd4j.argMax(fineClasses, 1))\n",
    "    val numberOfCoarseCorrectLabels = isCoarseClassCorrect.sumT\n",
    "    val numberOfFineCorrectLabels = isFineClassCorrect.sumT\n",
    "    val numberOfCorrectLabels = (isCoarseClassCorrect * isFineClassCorrect).sumT\n",
    "    val coarseAccuracyRate = numberOfCoarseCorrectLabels / imageCount\n",
    "    val fineAccuracyRate = numberOfFineCorrectLabels / imageCount\n",
    "    val finalAccuracyRate = numberOfCorrectLabels / imageCount\n",
    "  \n",
    "    (coarseAccuracyRate, fineAccuracyRate, finalAccuracyRate)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtrainAndCalculateAccuracyRate\u001b[39m"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trainAndCalculateAccuracyRate(coarseClass: Int, trainData: Cifar100.Batch): Future[(Loss, CoarseAccuracyRate, FineAccuracyRate, AccuracyRate)] = {\n",
    "  @monadic[Do]\n",
    "  def doTrain(images: INDArray,\n",
    "              fineClasses: INDArray,\n",
    "              coarseClasses: INDArray,\n",
    "              coarseClass: Int) = {\n",
    "    val imageCount = images.shape()(0)\n",
    "    // N * NumberOfFilters * 32 * 32\n",
    "    val coarseCNNOutput = coarseSubNet(images)\n",
    "    \n",
    "    val coarseStage2Output = coarseStage2Layers(coarseCNNOutput)\n",
    "    \n",
    "    // N * 20\n",
    "    val coarseSoftMaxOutput = softmax(coarseMaxPoolThenFC(coarseStage2Output, imageCount))\n",
    "    val coarseLoss = lossFunction(coarseSoftMaxOutput, coarseClasses)\n",
    "\n",
    "    val fineOutput = fineSubNet(coarseClass, coarseCNNOutput)\n",
    "    val fineSoftMaxOutput =\n",
    "      fineFCThenSoftmax(fineOutput, coarseClass, imageCount, NumberOfFilters * 16 * 16)\n",
    "    val fineLoss = lossFunction(fineSoftMaxOutput, fineClasses)\n",
    "    val lossLayer = coarseLoss + fineLoss\n",
    "\n",
    "    val lossTape: Tape[Double, Double] = lossLayer.forward.each\n",
    "\n",
    "    val backwardFuture = lossTape.backward(Do.now(1.0))\n",
    "    Do.garbageCollected(backwardFuture).each\n",
    "\n",
    "    val loss: Double = lossTape.data\n",
    "\n",
    "    val coarsePossibility = coarseSoftMaxOutput.forward.each.data\n",
    "    val finePossibility = fineSoftMaxOutput.forward.each.data\n",
    "\n",
    "    val (coarseAccuracyRate, fineAccuracyRate, finalAccuracyRate) = accuracyRate(coarsePossibility, finePossibility, coarseClass, fineClasses, imageCount)\n",
    "\n",
    "    (loss, coarseAccuracyRate, fineAccuracyRate, finalAccuracyRate)\n",
    "  }\n",
    "\n",
    "  doTrain(trainData.pixels, trainData.localFineClasses, trainData.coarseClasses, coarseClass).run\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mpredict\u001b[39m"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(images: INDArray): Future[(Int, Int)] = {\n",
    "\n",
    "  @monadic[Do]\n",
    "  def doPredict(images: INDArray, imageCount: Int): Do[(Int, Int)] = {\n",
    "    import org.nd4s.Implicits._\n",
    "    val coarseCNNOutput = coarseSubNet(images)\n",
    "    val coarseFCOutput = coarseMaxPoolThenFC(coarseCNNOutput, imageCount)\n",
    "    val coarseClass: Int = Nd4j.argMax(coarseFCOutput.forward.each.data, 1).get(0).toInt\n",
    "\n",
    "    val fineOutput = fineSubNet(coarseClass, coarseCNNOutput)\n",
    "    val fineSoftMaxOutput = fineFCThenSoftmax(fineOutput, coarseClass, imageCount, NumberOfFilters * 16 * 16)\n",
    "    val fineClass: Int = Nd4j.argMax(fineSoftMaxOutput.forward.each.data, 1).get(0).toInt\n",
    "    (coarseClass, fineClass)\n",
    "  }\n",
    "\n",
    "  val imageCount = images.shape()(0)\n",
    "\n",
    "  doPredict(images, imageCount).run\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscalaz.Semigroup\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.INDArrayLayers.MultipleException\n",
       "\u001b[39m\n",
       "\u001b[36mthrowableSemigroup\u001b[39m: \u001b[32mAnyRef\u001b[39m with \u001b[32mscalaz\u001b[39m.\u001b[32mSemigroup\u001b[39m[\u001b[32mThrowable\u001b[39m] = $sess.cmd25Wrapper$Helper$$anon$1@2c1ba05f"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scalaz.Semigroup\n",
    "import com.thoughtworks.deeplearning.plugins.INDArrayLayers.MultipleException\n",
    "implicit val throwableSemigroup = new Semigroup[Throwable] {\n",
    "  override def append(f1: Throwable, f2: => Throwable): Throwable =\n",
    "    f1 match {\n",
    "      case MultipleException(exceptionSet1) =>\n",
    "        f2 match {\n",
    "          case MultipleException(exceptionSet2) => MultipleException(exceptionSet1 ++ exceptionSet2)\n",
    "          case _: Throwable                     => MultipleException(exceptionSet1 + f2)\n",
    "        }\n",
    "      case _: Throwable =>\n",
    "        f2 match {\n",
    "          case MultipleException(exceptionSet2) => MultipleException(exceptionSet2 + f1)\n",
    "          case _: Throwable                     => MultipleException(Set(f1, f2))\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36misShuttingDown\u001b[39m: \u001b[32mBoolean\u001b[39m = \u001b[32mfalse\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mshutdown\u001b[39m"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@volatile\n",
    "var isShuttingDown: Boolean = false\n",
    "\n",
    "def shutdown(): Unit = {\n",
    "    isShuttingDown = true\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mCoarseClass\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mIterationId\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mEpoch\u001b[39m"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type CoarseClass = Int\n",
    "type IterationId = Int\n",
    "final class Epoch(epochId: Int, batchSize: Int, maxSamplesPerCoarseClass: Int) {\n",
    "    val batches: Iterator[(CoarseClass, Cifar100.Batch)] = cifar100.epochByCoarseClass(batchSize, maxSamplesPerCoarseClass)\n",
    "    var nextIterationId = 0\n",
    "    def nextBatch(): Option[((CoarseClass, Cifar100.Batch), IterationId)] = {\n",
    "        synchronized {\n",
    "            if (batches.hasNext) {\n",
    "                val currentIterationId = nextIterationId\n",
    "                if (currentIterationId % 100 == 0) {\n",
    "                    backup()\n",
    "                }\n",
    "                nextIterationId += 1\n",
    "                val result = ((batches.next()), currentIterationId)\n",
    "                Some(result)\n",
    "            } else {\n",
    "                None\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def run(): Future[Unit] = {\n",
    "        nextBatch() match {\n",
    "            case Some(((coarseClass, batch), i)) if !isShuttingDown => \n",
    "                trainAndCalculateAccuracyRate(coarseClass, batch).flatMap {\n",
    "                    case (loss, coarseAccuracyRate, fineAccuracyRate, accuracyRate) =>\n",
    "                        hyperparameters.logger.info(f\"epoch=$epochId%03d\\titeration=$i%05d\\tbatchSize=$batchSize\\tcoarseClass=$coarseClass%02d\\tloss=$loss%.7f\\tcoarseAccuracyRate=$coarseAccuracyRate%.3f\\tfineAccuracyRate=$fineAccuracyRate%.3f\\taccuracyRate=$accuracyRate%.3f\")\n",
    "                        run()\n",
    "                }   \n",
    "            case _ =>\n",
    "                Future.now(())                     \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mstartEpoch\u001b[39m"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def startEpoch(batchSize: Int, numberOfEpoches: Int, numberOfConcurrenctTrainings: Int, maxSamplesPerCoarseClass: Int): Unit = {\n",
    "    isShuttingDown = false\n",
    "    import scalaz.Monoid\n",
    "    import scalaz.Tags.Parallel\n",
    "\n",
    "    @monadic[Future]\n",
    "    def trainTask: Future[Unit] = {\n",
    "        for (epochId <- 1 |=> numberOfEpoches) {\n",
    "            hyperparameters.logger.info(s\"Epoch $epochId\")\n",
    "            val epoch = new Epoch(epochId, batchSize, maxSamplesPerCoarseClass)\n",
    "            \n",
    "            val fork = (1 |=> numberOfConcurrenctTrainings).foldMap { futureId: Int =>\n",
    "                Parallel(epoch.run())\n",
    "            }(Monoid.liftMonoid[ParallelFuture, Unit](futureParallelApplicative, scalaz.std.anyVal.unitInstance))\n",
    "            Parallel.unwrap(fork).each\n",
    "        }\n",
    "    }\n",
    "\n",
    "    trainTask.onComplete {\n",
    "        case util.Success(s) =>\n",
    "        case util.Failure(e) =>\n",
    "            hyperparameters.logger.log(java.util.logging.Level.SEVERE, \"Exception thrown during training\", e)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.props(\"org.bytedeco.javacpp.maxbytes\") = \"28g\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "startEpoch(batchSize = 4, numberOfEpoches = 500, numberOfConcurrenctTrainings = 4, maxSamplesPerCoarseClass = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "// @monadic[Future]\n",
    "// def trainTask: Future[Unit] = {\n",
    "//   val lossStream: Stream[TrainResult] =\n",
    "//     (for (_ <- (0 until 200).toStream) yield {\n",
    "//       val randomIndex = Utils.getRandomIndex(NumberOfTrainSamples)\n",
    "//       (for (times <- (0 until NumberOfTrainSamples / batchSize).toStream) yield {\n",
    "//         val slicedIndexArray = Utils.sliceIndexArray(randomIndex, times, MiniBatchSize)\n",
    "//         val trainData = ReadCIFARToNDArray.processSGDTrainData(slicedIndexArray)\n",
    "//         for (index <- trainData.indices.toStream) yield {\n",
    "//           val currentInput = trainData(index)\n",
    "//           val futureTrainResult: Future[TrainResult] = train(currentInput)\n",
    "//           val trainResult = futureTrainResult.each\n",
    "//           println(\"loss:\" + trainResult.loss)\n",
    "//           println(\"coarseAcc:\" + trainResult.coarseAcc)\n",
    "//           println(\"fineAcc:\" + trainResult.fineAcc)\n",
    "//           trainResult\n",
    "//         }\n",
    "//       }).flatten\n",
    "//     }).flatten\n",
    "//   trainResultSeq = IndexedSeq.concat(lossStream)\n",
    "// }\n",
    "\n",
    "// var lossSeq: IndexedSeq[Double] = IndexedSeq.empty\n",
    "\n",
    "// @monadic[Future]\n",
    "// val trainTask0: Future[Unit] = {\n",
    "//   val lossStream: Stream[Double] =\n",
    "//     (for (_ <- (0 until 500).toStream) yield {\n",
    "//       System.gc()\n",
    "//       val randomIndex = Utils.getRandomIndex(NumberOfTrainSamples)\n",
    "//       (for (times <- (0 until NumberOfTrainSamples / batchSize).toStream) yield {\n",
    "//         val slicedIndexArray =\n",
    "//           Utils.sliceIndexArray(randomIndex, times, MiniBatchSize)\n",
    "//         val trainData =\n",
    "//           ReadCIFARToNDArray.processSGDTrainData(slicedIndexArray)\n",
    "//         for (index <- trainData.indices.toStream) yield {\n",
    "//           val currentInput = trainData(index)\n",
    "//           val futureTrainResult: Future[Double] = train0(currentInput)\n",
    "//           val loss = futureTrainResult.each\n",
    "//           println(\"loss:\" + loss)\n",
    "\n",
    "//           if (loss.isNaN) {\n",
    "//             sys.exit(-11111111)\n",
    "//           }\n",
    "\n",
    "//           loss\n",
    "//         }\n",
    "//       }).flatten\n",
    "//     }).flatten\n",
    "//   lossSeq = IndexedSeq.concat(lossStream)\n",
    "// }\n",
    "\n",
    "// val startTime = LocalTime.now()\n",
    "// //Await.result(trainTask.toScalaFuture, Duration.Inf)\n",
    "// Await.result(trainTask0.toScalaFuture, Duration.Inf)\n",
    "// val endTime = LocalTime.now()\n",
    "\n",
    "// //  private val resultTuple\n",
    "// //    : (IndexedSeq[Double], IndexedSeq[Double], IndexedSeq[Double]) =\n",
    "// //    trainResultSeq.unzip3(result =>\n",
    "// //      (result.loss, result.coarseAcc, result.fineAcc))\n",
    "// //\n",
    "// //  Seq(\n",
    "// //    Scatter(trainResultSeq.indices, resultTuple._1, name = \"loss\"),\n",
    "// //    Scatter(trainResultSeq.indices, resultTuple._2, name = \"coarseAcc\"),\n",
    "// //    Scatter(trainResultSeq.indices, resultTuple._3, name = \"fineAcc\")\n",
    "// //  ).plot(title = \"loss & acc by time\")\n",
    "\n",
    "// def calculatePredictAcc(): (Double, Double) = {\n",
    "\n",
    "//   def calculatePredictResult: IndexedSeq[(Int, Int)] = {\n",
    "//     for (testItem <- testData)\n",
    "//       yield {\n",
    "//         val futurePredictResult: Future[PredictResult] = predict(testItem.imageData)\n",
    "//         val PredictResult(predictCoarse, predictFine) =\n",
    "//           Await.result(futurePredictResult.toScalaFuture, Duration.Inf)\n",
    "//         if (predictCoarse == testItem.coarse) {\n",
    "//           (1, Utils.isSameThenOne(predictFine, testItem.fine))\n",
    "//         } else {\n",
    "//           (0, 0)\n",
    "//         }\n",
    "//       }\n",
    "//   }\n",
    "\n",
    "//   val predictResult: IndexedSeq[(Int, Int)] = calculatePredictResult\n",
    "//   val resultTuple: (IndexedSeq[Int], IndexedSeq[Int]) = predictResult.unzip\n",
    "//   val total = resultTuple._1.size\n",
    "//   (resultTuple._1.sum / total, resultTuple._2.sum / total)\n",
    "// }\n",
    "\n",
    "// val (coarseAcc, fineAcc) = calculatePredictAcc()\n",
    "\n",
    "// println(s\"The coarse accuracy is $coarseAcc ,The fine accuracy is $fineAcc , start at $startTime , end at $endTime\")\n",
    "\n",
    "// Seq(\n",
    "//   Scatter(lossSeq.indices, lossSeq, name = \"loss\")\n",
    "// ).plot(title = s\"loss by time - learningRate : $learningRate, start at $startTime , end at $endTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
