{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "In this article, we will use [softmax](https://en.wikipedia.org/wiki/Softmax_function) classifier to build a simple image classification neural network with an accuracy of 32%. In a Softmax classifier, binary logic is generalized and regressed to multiple logic. Softmax classifier will output the probability of the corresponding category.\n",
    "\n",
    "We will first define a softmax classifier, then use the training set of [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) to train the neural network, and finally use the test set to verify the accuracy of the neural network.\n",
    "\n",
    "Letâ€™s get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the previous course [GettingStarted](https://thoughtworksinc.github.io/DeepLearning.scala/demo/GettingStarted.html), we need to introduce each class of DeepLearning.scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mjava.lang.InterruptedException\u001b[39m",
      "  java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(\u001b[32mAbstractQueuedSynchronizer.java\u001b[39m:\u001b[32m2067\u001b[39m)",
      "  java.util.concurrent.ThreadPoolExecutor.awaitTermination(\u001b[32mThreadPoolExecutor.java\u001b[39m:\u001b[32m1475\u001b[39m)",
      "  java.util.concurrent.Executors$DelegatedExecutorService.awaitTermination(\u001b[32mExecutors.java\u001b[39m:\u001b[32m675\u001b[39m)",
      "  coursier.TermDisplay.stopDidPrintSomething(\u001b[32mTermDisplay.scala\u001b[39m:\u001b[32m462\u001b[39m)",
      "  coursier.TermDisplay.stop(\u001b[32mTermDisplay.scala\u001b[39m:\u001b[32m468\u001b[39m)",
      "  ammonite.runtime.tools.DependencyThing.resolveArtifact(\u001b[32mDependencyThing.scala\u001b[39m:\u001b[32m87\u001b[39m)",
      "  ammonite.interp.Interpreter.loadIvy(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m658\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy$$anonfun$resolve$2.liftedTree1$1(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m182\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy$$anonfun$resolve$2.apply(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m182\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy$$anonfun$resolve$2.apply(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m176\u001b[39m)",
      "  ammonite.util.Res$Success.flatMap(\u001b[32mRes.scala\u001b[39m:\u001b[32m58\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy.resolve(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m176\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy$$anonfun$handle$4$$anonfun$apply$3.apply(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m191\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy$$anonfun$handle$4$$anonfun$apply$3.apply(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m191\u001b[39m)",
      "  ammonite.util.Res$$anonfun$1.apply(\u001b[32mRes.scala\u001b[39m:\u001b[32m34\u001b[39m)",
      "  ammonite.util.Res$$anonfun$1.apply(\u001b[32mRes.scala\u001b[39m:\u001b[32m31\u001b[39m)",
      "  scala.collection.LinearSeqOptimized$class.foldLeft(\u001b[32mLinearSeqOptimized.scala\u001b[39m:\u001b[32m124\u001b[39m)",
      "  scala.collection.immutable.List.foldLeft(\u001b[32mList.scala\u001b[39m:\u001b[32m84\u001b[39m)",
      "  ammonite.util.Res$.map(\u001b[32mRes.scala\u001b[39m:\u001b[32m31\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy$$anonfun$handle$4.apply(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m191\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy$$anonfun$handle$4.apply(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m190\u001b[39m)",
      "  ammonite.util.Res$Success.flatMap(\u001b[32mRes.scala\u001b[39m:\u001b[32m58\u001b[39m)",
      "  ammonite.runtime.ImportHook$BaseIvy.handle(\u001b[32mImportHook.scala\u001b[39m:\u001b[32m190\u001b[39m)",
      "  ammonite.interp.Interpreter$$anonfun$resolveSingleImportHook$3.apply(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m181\u001b[39m)",
      "  ammonite.interp.Interpreter$$anonfun$resolveSingleImportHook$3.apply(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m180\u001b[39m)",
      "  ammonite.util.Res$Success.flatMap(\u001b[32mRes.scala\u001b[39m:\u001b[32m58\u001b[39m)",
      "  ammonite.interp.Interpreter.resolveSingleImportHook(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m180\u001b[39m)",
      "  ammonite.interp.Interpreter$$anonfun$resolveImportHooks$2.apply(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m229\u001b[39m)",
      "  ammonite.interp.Interpreter$$anonfun$resolveImportHooks$2.apply(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m229\u001b[39m)",
      "  ammonite.util.Res$$anonfun$1.apply(\u001b[32mRes.scala\u001b[39m:\u001b[32m34\u001b[39m)",
      "  ammonite.util.Res$$anonfun$1.apply(\u001b[32mRes.scala\u001b[39m:\u001b[32m31\u001b[39m)",
      "  scala.collection.IndexedSeqOptimized$class.foldl(\u001b[32mIndexedSeqOptimized.scala\u001b[39m:\u001b[32m57\u001b[39m)",
      "  scala.collection.IndexedSeqOptimized$class.foldLeft(\u001b[32mIndexedSeqOptimized.scala\u001b[39m:\u001b[32m66\u001b[39m)",
      "  scala.collection.mutable.ArrayBuffer.foldLeft(\u001b[32mArrayBuffer.scala\u001b[39m:\u001b[32m48\u001b[39m)",
      "  ammonite.util.Res$.map(\u001b[32mRes.scala\u001b[39m:\u001b[32m31\u001b[39m)",
      "  ammonite.interp.Interpreter.resolveImportHooks(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m229\u001b[39m)",
      "  ammonite.interp.Interpreter$$anonfun$processLine$2.apply(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m243\u001b[39m)",
      "  ammonite.interp.Interpreter$$anonfun$processLine$2.apply(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m239\u001b[39m)",
      "  ammonite.util.Catching.flatMap(\u001b[32mRes.scala\u001b[39m:\u001b[32m109\u001b[39m)",
      "  ammonite.interp.Interpreter.processLine(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m239\u001b[39m)",
      "  jupyter.scala.Interp$$anonfun$8$$anonfun$apply$10$$anonfun$apply$11.apply(\u001b[32mInterp.scala\u001b[39m:\u001b[32m147\u001b[39m)",
      "  jupyter.scala.Interp$$anonfun$8$$anonfun$apply$10$$anonfun$apply$11.apply(\u001b[32mInterp.scala\u001b[39m:\u001b[32m146\u001b[39m)",
      "  jupyter.scala.Capture$$anonfun$jupyter$scala$Capture$$withErr$1.apply(\u001b[32mCapture.scala\u001b[39m:\u001b[32m46\u001b[39m)",
      "  scala.util.DynamicVariable.withValue(\u001b[32mDynamicVariable.scala\u001b[39m:\u001b[32m58\u001b[39m)",
      "  scala.Console$.withErr(\u001b[32mConsole.scala\u001b[39m:\u001b[32m80\u001b[39m)",
      "  jupyter.scala.Capture$.jupyter$scala$Capture$$withErr(\u001b[32mCapture.scala\u001b[39m:\u001b[32m42\u001b[39m)",
      "  jupyter.scala.Capture$$anonfun$3.apply(\u001b[32mCapture.scala\u001b[39m:\u001b[32m59\u001b[39m)",
      "  jupyter.scala.Capture$$anonfun$withOut$1.apply(\u001b[32mCapture.scala\u001b[39m:\u001b[32m37\u001b[39m)",
      "  scala.util.DynamicVariable.withValue(\u001b[32mDynamicVariable.scala\u001b[39m:\u001b[32m58\u001b[39m)",
      "  scala.Console$.withOut(\u001b[32mConsole.scala\u001b[39m:\u001b[32m53\u001b[39m)",
      "  jupyter.scala.Capture$.withOut(\u001b[32mCapture.scala\u001b[39m:\u001b[32m33\u001b[39m)",
      "  jupyter.scala.Capture$.withOutAndErr(\u001b[32mCapture.scala\u001b[39m:\u001b[32m59\u001b[39m)",
      "  jupyter.scala.Capture$.apply(\u001b[32mCapture.scala\u001b[39m:\u001b[32m106\u001b[39m)",
      "  jupyter.scala.Interp.jupyter$scala$Interp$$capturingOutput(\u001b[32mInterp.scala\u001b[39m:\u001b[32m104\u001b[39m)",
      "  jupyter.scala.Interp$$anonfun$8$$anonfun$apply$10.apply(\u001b[32mInterp.scala\u001b[39m:\u001b[32m146\u001b[39m)",
      "  jupyter.scala.Interp$$anonfun$8$$anonfun$apply$10.apply(\u001b[32mInterp.scala\u001b[39m:\u001b[32m142\u001b[39m)",
      "  jupyter.scala.Scoped$$anonfun$flatMap$1.apply(\u001b[32mSignaller.scala\u001b[39m:\u001b[32m45\u001b[39m)",
      "  jupyter.scala.Signaller.apply(\u001b[32mSignaller.scala\u001b[39m:\u001b[32m30\u001b[39m)",
      "  jupyter.scala.Scoped$class.flatMap(\u001b[32mSignaller.scala\u001b[39m:\u001b[32m45\u001b[39m)",
      "  jupyter.scala.Signaller.flatMap(\u001b[32mSignaller.scala\u001b[39m:\u001b[32m12\u001b[39m)",
      "  jupyter.scala.Interp$$anonfun$8.apply(\u001b[32mInterp.scala\u001b[39m:\u001b[32m142\u001b[39m)",
      "  jupyter.scala.Interp$$anonfun$8.apply(\u001b[32mInterp.scala\u001b[39m:\u001b[32m133\u001b[39m)",
      "  ammonite.util.Res$Success.flatMap(\u001b[32mRes.scala\u001b[39m:\u001b[32m58\u001b[39m)",
      "  jupyter.scala.Interp.interpret(\u001b[32mInterp.scala\u001b[39m:\u001b[32m133\u001b[39m)",
      "  jupyter.kernel.interpreter.InterpreterHandler$$anonfun$jupyter$kernel$interpreter$InterpreterHandler$$execute$1$$anonfun$apply$6.apply(\u001b[32mInterpreterHandler.scala\u001b[39m:\u001b[32m112\u001b[39m)",
      "  jupyter.kernel.interpreter.InterpreterHandler$$anonfun$jupyter$kernel$interpreter$InterpreterHandler$$execute$1$$anonfun$apply$6.apply(\u001b[32mInterpreterHandler.scala\u001b[39m:\u001b[32m94\u001b[39m)",
      "  jupyter.kernel.interpreter.InterpreterHandler$$anonfun$jupyter$kernel$interpreter$InterpreterHandler$$publishing$1$$anonfun$2.apply(\u001b[32mInterpreterHandler.scala\u001b[39m:\u001b[32m59\u001b[39m)",
      "  jupyter.kernel.interpreter.InterpreterHandler$$anonfun$jupyter$kernel$interpreter$InterpreterHandler$$publishing$1$$anonfun$2.apply(\u001b[32mInterpreterHandler.scala\u001b[39m:\u001b[32m59\u001b[39m)",
      "  scalaz.concurrent.Task$.Try(\u001b[32mTask.scala\u001b[39m:\u001b[32m457\u001b[39m)",
      "  scalaz.concurrent.Task$$anonfun$unsafeStart$1.apply(\u001b[32mTask.scala\u001b[39m:\u001b[32m363\u001b[39m)",
      "  scalaz.concurrent.Task$$anonfun$unsafeStart$1.apply(\u001b[32mTask.scala\u001b[39m:\u001b[32m363\u001b[39m)",
      "  scalaz.concurrent.Future$$anonfun$apply$15$$anon$3.call(\u001b[32mFuture.scala\u001b[39m:\u001b[32m432\u001b[39m)",
      "  scalaz.concurrent.Future$$anonfun$apply$15$$anon$3.call(\u001b[32mFuture.scala\u001b[39m:\u001b[32m432\u001b[39m)",
      "  java.util.concurrent.FutureTask.run(\u001b[32mFutureTask.java\u001b[39m:\u001b[32m266\u001b[39m)",
      "  java.util.concurrent.ThreadPoolExecutor.runWorker(\u001b[32mThreadPoolExecutor.java\u001b[39m:\u001b[32m1149\u001b[39m)",
      "  java.util.concurrent.ThreadPoolExecutor$Worker.run(\u001b[32mThreadPoolExecutor.java\u001b[39m:\u001b[32m624\u001b[39m)",
      "  java.lang.Thread.run(\u001b[32mThread.java\u001b[39m:\u001b[32m748\u001b[39m)"
     ]
    }
   ],
   "source": [
    "import $ivy.`org.nd4j::nd4s:0.8.0`\n",
    "import $ivy.`org.nd4j:nd4j-api:0.8.0`\n",
    "import $ivy.`org.nd4j:nd4j-cuda-8.0-platform:0.8.0`\n",
    "// import $ivy.`org.nd4j:nd4j-native-platform:0.8.0`\n",
    "import $ivy.`com.chuusai::shapeless:2.3.2`\n",
    "import $ivy.`org.rauschig:jarchivelib:0.5.0`\n",
    "import $ivy.`com.thoughtworks.deeplearning::plugins-builtins:2.0.1`\n",
    "import $ivy.`org.plotly-scala::plotly-jupyter-scala:0.3.2`\n",
    "import $ivy.`com.thoughtworks.each::each:3.3.1`\n",
    "import $plugin.$ivy.`org.scalamacros:paradise_2.11.11:2.1.0`\n",
    "\n",
    "import scala.concurrent.ExecutionContext.Implicits.global\n",
    "import org.nd4j.linalg.api.ndarray.INDArray\n",
    "import org.nd4j.linalg.factory.Nd4j\n",
    "import com.thoughtworks.deeplearning.DeepLearning\n",
    "import com.thoughtworks.deeplearning.plugins._\n",
    "import com.thoughtworks.feature.Factory\n",
    "import plotly._\n",
    "import plotly.element._\n",
    "import plotly.layout._\n",
    "import plotly.JupyterScala._\n",
    "plotly.JupyterScala.init()\n",
    "\n",
    "import com.thoughtworks.future._\n",
    "import scala.concurrent.Await\n",
    "import scala.concurrent.duration.Duration\n",
    "import com.thoughtworks.each.Monadic._\n",
    "import scalaz.std.stream._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the line numbers outputted by `jupyter-scala` and to make sure that the page output will not be too long, we need to set `pprintConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprintConfig() = pprintConfig().copy(height = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your own neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate need to be set for the full connection layer. Learning rate visually describes the change rate of `weight`. A too-low learning rate will result in slow decrease of `loss`, which will require longer time for training; A too-high learning rate will result in rapid decrease of `loss` at first while fluctuation around the lowest point afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-implicitssingleton_2.11/2.0.0-RC5/plugins-implicitssingleton_2.11-2.0.0-RC5.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-weights_2.11/2.0.0-RC5/plugins-weights_2.11-2.0.0-RC5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-implicitssingleton_2.11/2.0.0-RC5/plugins-implicitssingleton_2.11-2.0.0-RC5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-weights_2.11/2.0.0-RC5/plugins-weights_2.11-2.0.0-RC5.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-weights_2.11/2.0.0-RC5/plugins-weights_2.11-2.0.0-RC5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-weights_2.11/2.0.0-RC5/plugins-weights_2.11-2.0.0-RC5.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-implicitssingleton_2.11/2.0.0-RC5/plugins-implicitssingleton_2.11-2.0.0-RC5.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-weights_2.11/2.0.0-RC5/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-implicitssingleton_2.11/2.0.0-RC5/plugins-implicitssingleton_2.11-2.0.0-RC5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-implicitssingleton_2.11/2.0.0-RC5/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-weights_2.11/2.0.0-RC5/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-implicitssingleton_2.11/2.0.0-RC5/\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-effect_2.11/7.2.11/scalaz-effect_2.11-7.2.11.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-effect_2.11/7.2.11/scalaz-effect_2.11-7.2.11.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.0/asynchronous_2.11-1.0.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.0/asynchronous_2.11-1.0.0.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/deeplearning_2.11/2.0.0-RC5/deeplearning_2.11-2.0.0-RC5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/deeplearning_2.11/2.0.0-RC5/deeplearning_2.11-2.0.0-RC5.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-effect_2.11/7.2.11/scalaz-effect_2.11-7.2.11.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.0/asynchronous_2.11-1.0.0.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-effect_2.11/7.2.11/scalaz-effect_2.11-7.2.11.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-effect_2.11/7.2.11/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.0/asynchronous_2.11-1.0.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.0/\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-effect_2.11/7.2.11/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/deeplearning_2.11/2.0.0-RC5/deeplearning_2.11-2.0.0-RC5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/deeplearning_2.11/2.0.0-RC5/deeplearning_2.11-2.0.0-RC5.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/deeplearning_2.11/2.0.0-RC5/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.0/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/deeplearning_2.11/2.0.0-RC5/\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.11/scalaz-core_2.11-7.2.11.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.11/scalaz-core_2.11-7.2.11.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.0/covariant_2.11-1.0.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.0/covariant_2.11-1.0.0.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.1/asynchronous_2.11-1.0.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.1/asynchronous_2.11-1.0.1.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.11/scalaz-core_2.11-7.2.11.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/tryt/covariant_2.11/2.0.1/covariant_2.11-2.0.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.0/covariant_2.11-1.0.0.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.11/scalaz-core_2.11-7.2.11.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/tryt/covariant_2.11/2.0.1/covariant_2.11-2.0.1.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.0/shared_2.11-1.0.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.0/covariant_2.11-1.0.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.0/shared_2.11-1.0.0.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.1/asynchronous_2.11-1.0.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.11/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/tryt/covariant_2.11/2.0.1/covariant_2.11-2.0.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.0/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/tryt/covariant_2.11/2.0.1/covariant_2.11-2.0.1.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/tryt/covariant_2.11/2.0.1/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.0/shared_2.11-1.0.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.0/shared_2.11-1.0.0.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.0/\n",
      "https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.1/â€¦ \n",
      "\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.11/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/tryt/covariant_2.11/2.0.1/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.0/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.0/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.1/asynchronous_2.11-1.0.1.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.1/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.1/\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-concurrent_2.11/7.2.11/scalaz-concurrent_2.11-7.2.11.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-concurrent_2.11/7.2.11/scalaz-concurrent_2.11-7.2.11.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.13/scalaz-core_2.11-7.2.13.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.1/covariant_2.11-1.0.1.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.1/covariant_2.11-1.0.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.13/scalaz-core_2.11-7.2.13.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-concurrent_2.11/7.2.11/scalaz-concurrent_2.11-7.2.11.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.1/shared_2.11-1.0.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.1/covariant_2.11-1.0.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.1/shared_2.11-1.0.1.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-concurrent_2.11/7.2.11/scalaz-concurrent_2.11-7.2.11.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-concurrent_2.11/7.2.11/\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.13/scalaz-core_2.11-7.2.13.pom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.1/covariant_2.11-1.0.1.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.1/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.1/shared_2.11-1.0.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.1/shared_2.11-1.0.1.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.13/scalaz-core_2.11-7.2.13.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.1/\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.13/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.1/\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-concurrent_2.11/7.2.11/\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.1/\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.13/\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/tryt/covariant_2.11/2.0.1/covariant_2.11-2.0.1.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/tryt/covariant_2.11/2.0.1/covariant_2.11-2.0.1.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-implicitssingleton_2.11/2.0.0-RC5/plugins-implicitssingleton_2.11-2.0.0-RC5.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-implicitssingleton_2.11/2.0.0-RC5/plugins-implicitssingleton_2.11-2.0.0-RC5.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-implicitssingleton_2.11/2.0.0-RC5/plugins-implicitssingleton_2.11-2.0.0-RC5.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.13/scalaz-core_2.11-7.2.13.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/tryt/covariant_2.11/2.0.1/covariant_2.11-2.0.1.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.13/scalaz-core_2.11-7.2.13.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-concurrent_2.11/7.2.11/scalaz-concurrent_2.11-7.2.11.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-implicitssingleton_2.11/2.0.0-RC5/plugins-implicitssingleton_2.11-2.0.0-RC5.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-concurrent_2.11/7.2.11/scalaz-concurrent_2.11-7.2.11.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-effect_2.11/7.2.11/scalaz-effect_2.11-7.2.11.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-concurrent_2.11/7.2.11/scalaz-concurrent_2.11-7.2.11.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-effect_2.11/7.2.11/scalaz-effect_2.11-7.2.11.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/tryt/covariant_2.11/2.0.1/covariant_2.11-2.0.1.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/deeplearning_2.11/2.0.0-RC5/deeplearning_2.11-2.0.0-RC5.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.13/scalaz-core_2.11-7.2.13.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/deeplearning_2.11/2.0.0-RC5/deeplearning_2.11-2.0.0-RC5.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/deeplearning_2.11/2.0.0-RC5/deeplearning_2.11-2.0.0-RC5.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.1/asynchronous_2.11-1.0.1.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/deeplearning_2.11/2.0.0-RC5/deeplearning_2.11-2.0.0-RC5.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.1/asynchronous_2.11-1.0.1.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-effect_2.11/7.2.11/scalaz-effect_2.11-7.2.11.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-weights_2.11/2.0.0-RC5/plugins-weights_2.11-2.0.0-RC5.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.1/asynchronous_2.11-1.0.1.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-weights_2.11/2.0.0-RC5/plugins-weights_2.11-2.0.0-RC5.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-weights_2.11/2.0.0-RC5/plugins-weights_2.11-2.0.0-RC5.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.1/shared_2.11-1.0.1.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/asynchronous_2.11/1.0.1/asynchronous_2.11-1.0.1.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.1/shared_2.11-1.0.1.jar.sha1\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-concurrent_2.â€¦ (33.24 %, 11406â€¦\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-effect_2.11/7â€¦ (2.99 %, 13170 â€¦\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (1.86 %, 221940â€¦\n",
      "\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-weights_2.11/2.0.0-RC5/plugins-weights_2.11-2.0.0-RC5.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.1/covariant_2.11-1.0.1.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.1/shared_2.11-1.0.1.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.1/covariant_2.11-1.0.1.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/shared_2.11/1.0.1/shared_2.11-1.0.1.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-indarrayweights_2.11/2.0.0-RC5/plugins-indarrayweights_2.11-2.0.0-RC5.jar\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-concurrent_2.â€¦ (80.99 %, 27790â€¦\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-effect_2.11/7â€¦ (29.62 %, 13044â€¦\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (4.20 %, 500468â€¦\n",
      "\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-concurrent_2.11/7.2.11/scalaz-concurrent_2.11-7.2.11.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-indarrayweights_2.11/2.0.0-RC5/plugins-indarrayweights_2.11-2.0.0-RC5.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.1/covariant_2.11-1.0.1.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-indarrayweights_2.11/2.0.0-RC5/plugins-indarrayweights_2.11-2.0.0-RC5.jar\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-effect_2.11/7â€¦ (56.28 %, 24789â€¦\n",
      "https://repo1.maven.org/maven2/com/thoughtworks/raii/covariantâ€¦ (54.83 %, 64911â€¦\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/deeplearning/plugins-indarrayweights_2.11/2.0.0-RC5/plugins-indarrayweights_2.11-2.0.0-RC5.jar.sha1\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (5.43 %, 647924â€¦\n",
      "\n",
      "Downloaded https://repo1.maven.org/maven2/com/thoughtworks/raii/covariant_2.11/1.0.1/covariant_2.11-1.0.1.jar\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-effect_2.11/7â€¦ (81.70 %, 35982â€¦\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (6.67 %, 795380â€¦\n",
      "\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-effect_2.11/7.2.11/scalaz-effect_2.11-7.2.11.jar\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (7.49 %, 893684â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (8.32 %, 991988â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (9.14 %, 109029â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (9.96 %, 118859â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (10.93 %, 13032â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (12.02 %, 14343â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (13.95 %, 16637â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (16.69 %, 19914â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (19.17 %, 22863â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (21.91 %, 26140â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (23.70 %, 28269â€¦\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (25.62 %, 30563â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (27.82 %, 33185â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (30.15 %, 35970â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (32.35 %, 38591â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (34.82 %, 41541â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (37.02 %, 44162â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (39.49 %, 47111â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (41.97 %, 50060â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (43.75 %, 52190â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (45.40 %, 54156â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (47.05 %, 56122â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (48.70 %, 58088â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (50.35 %, 60054â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (51.86 %, 61857â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (53.09 %, 63331â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (54.47 %, 64970â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (55.84 %, 66608â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (57.35 %, 68410â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (58.86 %, 70213â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (60.65 %, 72342â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (63.12 %, 75292â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (66.69 %, 79551â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (71.36 %, 85122â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (75.76 %, 90365â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (78.23 %, 93314â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (80.01 %, 95444â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (80.01 %, 95444â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (82.21 %, 98065â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (83.04 %, 99048â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (83.93 %, 10011â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (84.82 %, 10117â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (85.78 %, 10232â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (86.33 %, 10298â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (87.02 %, 10380â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (87.57 %, 10445â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (88.23 %, 10524â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (88.94 %, 10609â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (89.77 %, 10707â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (90.59 %, 10806â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (91.41 %, 10904â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (92.65 %, 11051â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (93.47 %, 11150â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (94.44 %, 11264â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (95.40 %, 11379â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (96.22 %, 11477â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (97.18 %, 11592â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (98.14 %, 11707â€¦\n",
      "\n",
      "https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2â€¦ (99.38 %, 11854â€¦\n",
      "\n",
      "Downloaded https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.2.13/scalaz-core_2.11-7.2.13.jar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Main1.sc:13: not found: type INDArray\n",
      "    override def delta: INDArray = {\n",
      "                        ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mammonite.util.CompilationError: Compilation Failed\u001b[39m",
      "  ammonite.interp.Interpreter$$anon$2$$anon$1.apply(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m700\u001b[39m)",
      "  $sess.cmd1Wrapper$Helper.<init>(\u001b[32mcmd1.sc\u001b[39m:\u001b[32m2\u001b[39m)",
      "  $sess.cmd1Wrapper.<init>(\u001b[32mcmd1.sc\u001b[39m:\u001b[32m85\u001b[39m)",
      "  $sess.cmd1$.<init>(\u001b[32mcmd1.sc\u001b[39m:\u001b[32m63\u001b[39m)",
      "  $sess.cmd1$.<clinit>(\u001b[32mcmd1.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "val INDArrayLearningRatePluginUrl = \"https://gist.githubusercontent.com/TerrorJack/118487016d7973d67feb489449dee156/raw/778bb1b68a664c752b0945111220326731310214/INDArrayLearningRate.sc\"\n",
    "interp.load(scala.io.Source.fromURL(new java.net.URL(INDArrayLearningRatePluginUrl)).mkString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Main1.sc:2: type INDArrayLayers is not a member of package com.thoughtworks.deeplearning.plugins\n",
      "extends com.thoughtworks.deeplearning.plugins.INDArrayLayers\n",
      "                                              ^Main1.sc:4: type Training is not a member of package com.thoughtworks.deeplearning.plugins\n",
      "with com.thoughtworks.deeplearning.plugins.Training\n",
      "                                           ^Main1.sc:5: type Operators is not a member of package com.thoughtworks.deeplearning.plugins\n",
      "with com.thoughtworks.deeplearning.plugins.Operators {\n",
      "                                           ^Main1.sc:15: object each is not a member of package com.thoughtworks\n",
      "  import com.thoughtworks.each.Monadic._\n",
      "                          ^Main1.sc:20: INDArrayLayers does not name a parent class of trait CNNs\n",
      "    extends super[INDArrayLayers].ImplicitsApi\n",
      "            ^Main1.sc:21: Training does not name a parent class of trait CNNs\n",
      "      with super[Training].ImplicitsApi\n",
      "           ^Main1.sc:22: Operators does not name a parent class of trait CNNs\n",
      "      with super[Operators].ImplicitsApi\n",
      "           ^Main1.sc:31: not found: type INDArrayLayer\n",
      "  def im2col[Operand0, Out <: INDArrayLayer](operand0: Operand0,\n",
      "                              ^Main1.sc:36: not found: value indArrayPartialApplyRawForward\n",
      "                                              layerImplicits: ImplicitApply.Aux[indArrayPartialApplyRawForward.Rest, Out]): Out = {\n",
      "                                                                                ^Main1.sc:37: not found: value INDArrayLayer\n",
      "    INDArrayLayer.unary(operand0) { data0: INDArray =>\n",
      "    ^Main1.sc:50: not found: type INDArrayLayer\n",
      "  def conv2d[Input, Weight, Bias, Out <: INDArrayLayer](input: Input,\n",
      "                                         ^Main1.sc:59: not found: value indArrayPartialApplyRawForward\n",
      "                                                         layerImplicits: ImplicitApply.Aux[indArrayPartialApplyRawForward.Rest, Out]): Out = {\n",
      "                                                                                           ^Main1.sc:61: not found: value INDArrayLayer\n",
      "    INDArrayLayer(monadic[Do] {\n",
      "    ^Main1.sc:61: not found: value monadic\n",
      "    INDArrayLayer(monadic[Do] {\n",
      "                  ^Main1.sc:62: value forward is not a member of type parameter Input\n",
      "      val inputShape = input.forward.each.data.shape\n",
      "                             ^Main1.sc:67: value forward is not a member of type parameter Weight\n",
      "      val numberOfKernels = weight.forward.each.data.shape.head\n",
      "                                   ^Main1.sc:72: value reshape is not a member of type parameter Weight\n",
      "      val reshapedWeight = weight.reshape(numberOfKernels, depthKernelKernel)\n",
      "                                  ^Main1.sc:82: not found: type INDArrayLayer\n",
      "  def maxPool[Operand0, Out <: INDArrayLayer](operand0: Operand0, poolSize: (Int, Int))(\n",
      "                               ^Main1.sc:84: not found: value indArrayPartialApplyRawForward\n",
      "    layerImplicits: ImplicitApply.Aux[indArrayPartialApplyRawForward.Rest, Out]): Out = {\n",
      "                                      ^Main1.sc:85: not found: value INDArrayLayer\n",
      "    INDArrayLayer.unary(operand0) { data0: INDArray =>\n",
      "    ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mammonite.util.CompilationError: Compilation Failed\u001b[39m",
      "  ammonite.interp.Interpreter$$anon$2$$anon$1.apply(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m700\u001b[39m)",
      "  $sess.cmd2Wrapper$Helper.<init>(\u001b[32mcmd2.sc\u001b[39m:\u001b[32m1\u001b[39m)",
      "  $sess.cmd2Wrapper.<init>(\u001b[32mcmd2.sc\u001b[39m:\u001b[32m81\u001b[39m)",
      "  $sess.cmd2$.<init>(\u001b[32mcmd2.sc\u001b[39m:\u001b[32m63\u001b[39m)",
      "  $sess.cmd2$.<clinit>(\u001b[32mcmd2.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "interp.load(scala.io.Source.fromURL(new java.net.URL(\"https://gist.github.com/Atry/15b7d9a4c63d95ad3d67e94bf20b4f69/raw/59f7ee4dff0dde3753f560633574265e950edc93/CNN.sc\")).mkString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Main1.sc:2: not found: value Factory\n",
      "  val hyperparameters = Factory[Builtins with CNNs with INDArrayLearningRate].newInstance(learningRate = 0.1)\n",
      "                        ^Main1.sc:2: not found: type Builtins\n",
      "  val hyperparameters = Factory[Builtins with CNNs with INDArrayLearningRate].newInstance(learningRate = 0.1)\n",
      "                                ^Main1.sc:2: not found: type CNNs\n",
      "  val hyperparameters = Factory[Builtins with CNNs with INDArrayLearningRate].newInstance(learningRate = 0.1)\n",
      "                                              ^Main1.sc:2: not found: type INDArrayLearningRate\n",
      "  val hyperparameters = Factory[Builtins with CNNs with INDArrayLearningRate].newInstance(learningRate = 0.1)\n",
      "                                                        ^Main1.sc:2: not found: value learningRate\n",
      "  val hyperparameters = Factory[Builtins with CNNs with INDArrayLearningRate].newInstance(learningRate = 0.1)\n",
      "                                                                                          ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mammonite.util.CompilationError: Compilation Failed\u001b[39m",
      "  ammonite.interp.Interpreter$$anon$2$$anon$1.apply(\u001b[32mInterpreter.scala\u001b[39m:\u001b[32m700\u001b[39m)",
      "  $sess.cmd3Wrapper$Helper.<init>(\u001b[32mcmd3.sc\u001b[39m:\u001b[32m1\u001b[39m)",
      "  $sess.cmd3Wrapper.<init>(\u001b[32mcmd3.sc\u001b[39m:\u001b[32m81\u001b[39m)",
      "  $sess.cmd3$.<init>(\u001b[32mcmd3.sc\u001b[39m:\u001b[32m63\u001b[39m)",
      "  $sess.cmd3$.<clinit>(\u001b[32mcmd3.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "// `interp.load` is a workaround for https://github.com/lihaoyi/Ammonite/issues/649 and https://github.com/scala/bug/issues/10390\n",
    "interp.load(\"\"\"\n",
    "  val hyperparameters = Factory[Builtins with CNNs with INDArrayLearningRate].newInstance(learningRate = 0.1)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `softmax` classifier (softmax classifier is a neural network combined by `softmax` and a full connection), we first need to write softmax function, formula: ![](https://www.zhihu.com/equation?tex=f_j%28z%29%3D%5Cfrac%7Be%5E%7Bz_j%7D%7D%7B%5Csum_ke%5E%7Bz_k%7D%7D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd4.sc:1: not found: value hyperparameters\n",
      "import hyperparameters.implicits._\n",
      "       ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "import hyperparameters.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd4.sc:1: not found: value hyperparameters\n",
      "import hyperparameters.INDArrayLayer\n",
      "       ^cmd4.sc:3: not found: type INDArrayLayer\n",
      "def softmax(scores: INDArrayLayer): INDArrayLayer = {\n",
      "                                    ^cmd4.sc:3: not found: type INDArrayLayer\n",
      "def softmax(scores: INDArrayLayer): INDArrayLayer = {\n",
      "                    ^cmd4.sc:4: not found: value hyperparameters\n",
      "  val expScores = hyperparameters.exp(scores)\n",
      "                  ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "import hyperparameters.INDArrayLayer\n",
    "\n",
    "def softmax(scores: INDArrayLayer): INDArrayLayer = {\n",
    "  val expScores = hyperparameters.exp(scores)\n",
    "  expScores / expScores.sum(1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd4.sc:2: not found: value hyperparameters\n",
      "val res4_1 = hyperparameters.logger.addHandler(fileHandler)\n",
      "             ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "val fileHandler = new java.util.logging.FileHandler(\"CNN%g.log\")\n",
    "hyperparameters.logger.addHandler(fileHandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose your  neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a full connection layer and [initialize Weight](https://github.com/ThoughtWorksInc/DeepLearning.scala/wiki/Getting-Started#231--weight-intialization), `Weight` shall be a two-dimension `INDArray` of `NumberOfPixels Ã— NumberOfClasses`. `scores` is the score of each image corresponding to each category, representing the feasible probability of each category corresponding to each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mNumberOfClasses\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m10\u001b[39m\n",
       "\u001b[36mNumberOfPixels\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m3072\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//10 label of CIFAR10 images(airplane,automobile,bird,cat,deer,dog,frog,horse,ship,truck)\n",
    "val NumberOfClasses: Int = 10\n",
    "val NumberOfPixels: Int = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd5.sc:1: not found: value hyperparameters\n",
      "import hyperparameters.INDArrayWeight\n",
      "       ^cmd5.sc:5: not found: value INDArrayWeight\n",
      "    INDArrayWeight(Nd4j.randn(Array(16, 3, 3, 3)) / math.sqrt(3 * 3 * 3 / 2))\n",
      "    ^cmd5.sc:5: not found: value Nd4j\n",
      "    INDArrayWeight(Nd4j.randn(Array(16, 3, 3, 3)) / math.sqrt(3 * 3 * 3 / 2))\n",
      "                   ^cmd5.sc:8: not found: value hyperparameters\n",
      "    hyperparameters.INDArrayWeight(Nd4j.zeros(16))\n",
      "    ^cmd5.sc:8: not found: value Nd4j\n",
      "    hyperparameters.INDArrayWeight(Nd4j.zeros(16))\n",
      "                                   ^cmd5.sc:13: not found: value INDArrayWeight\n",
      "    INDArrayWeight(Nd4j.randn(Array(18, 16, 3, 3)) / math.sqrt(16 * 3 * 3 / 2))\n",
      "    ^cmd5.sc:13: not found: value Nd4j\n",
      "    INDArrayWeight(Nd4j.randn(Array(18, 16, 3, 3)) / math.sqrt(16 * 3 * 3 / 2))\n",
      "                   ^cmd5.sc:16: not found: value hyperparameters\n",
      "    hyperparameters.INDArrayWeight(Nd4j.zeros(18))\n",
      "    ^cmd5.sc:16: not found: value Nd4j\n",
      "    hyperparameters.INDArrayWeight(Nd4j.zeros(18))\n",
      "                                   ^cmd5.sc:21: not found: value INDArrayWeight\n",
      "    INDArrayWeight(Nd4j.randn(Array(20, 18, 3, 3)) / math.sqrt(18 * 3 * 3 / 2))\n",
      "    ^cmd5.sc:21: not found: value Nd4j\n",
      "    INDArrayWeight(Nd4j.randn(Array(20, 18, 3, 3)) / math.sqrt(18 * 3 * 3 / 2))\n",
      "                   ^cmd5.sc:24: not found: value hyperparameters\n",
      "    hyperparameters.INDArrayWeight(Nd4j.zeros(20))\n",
      "    ^cmd5.sc:24: not found: value Nd4j\n",
      "    hyperparameters.INDArrayWeight(Nd4j.zeros(20))\n",
      "                                   ^cmd5.sc:29: not found: value INDArrayWeight\n",
      "    INDArrayWeight(Nd4j.randn(Array(22, 20, 3, 3)) / math.sqrt(20 * 3 * 3 / 2))\n",
      "    ^cmd5.sc:29: not found: value Nd4j\n",
      "    INDArrayWeight(Nd4j.randn(Array(22, 20, 3, 3)) / math.sqrt(20 * 3 * 3 / 2))\n",
      "                   ^cmd5.sc:32: not found: value hyperparameters\n",
      "    hyperparameters.INDArrayWeight(Nd4j.zeros(22))\n",
      "    ^cmd5.sc:32: not found: value Nd4j\n",
      "    hyperparameters.INDArrayWeight(Nd4j.zeros(22))\n",
      "                                   ^cmd5.sc:37: not found: value INDArrayWeight\n",
      "    INDArrayWeight(Nd4j.randn(Array(24, 22, 3, 3)) / math.sqrt(22 * 3 * 3 / 2))\n",
      "    ^cmd5.sc:37: not found: value Nd4j\n",
      "    INDArrayWeight(Nd4j.randn(Array(24, 22, 3, 3)) / math.sqrt(22 * 3 * 3 / 2))\n",
      "                   ^cmd5.sc:40: not found: value hyperparameters\n",
      "    hyperparameters.INDArrayWeight(Nd4j.zeros(24))\n",
      "    ^cmd5.sc:40: not found: value Nd4j\n",
      "    hyperparameters.INDArrayWeight(Nd4j.zeros(24))\n",
      "                                   ^cmd5.sc:46: not found: value INDArrayWeight\n",
      "    INDArrayWeight(Nd4j.randn(Array(24, 10)) / math.sqrt(24 / 2))\n",
      "    ^cmd5.sc:46: not found: value Nd4j\n",
      "    INDArrayWeight(Nd4j.randn(Array(24, 10)) / math.sqrt(24 / 2))\n",
      "                   ^cmd5.sc:49: not found: value hyperparameters\n",
      "    hyperparameters.INDArrayWeight(Nd4j.zeros(10))\n",
      "    ^cmd5.sc:49: not found: value Nd4j\n",
      "    hyperparameters.INDArrayWeight(Nd4j.zeros(10))\n",
      "                                   ^cmd5.sc:52: not found: type INDArrayLayer\n",
      "def myNeuralNetwork(input: INDArray): INDArrayLayer = {\n",
      "                                      ^cmd5.sc:52: not found: type INDArray\n",
      "def myNeuralNetwork(input: INDArray): INDArrayLayer = {\n",
      "                           ^cmd5.sc:53: not found: value hyperparameters\n",
      "    import hyperparameters.max\n",
      "           ^cmd5.sc:54: not found: value hyperparameters\n",
      "    import hyperparameters.maxPool\n",
      "           ^cmd5.sc:55: not found: value hyperparameters\n",
      "    import hyperparameters.conv2d\n",
      "           ^cmd5.sc:56: not found: value maxPool\n",
      "    val layer1 = maxPool(max(conv2d(input.reshape(input.shape()(0), 3, 32, 32), weight1, bias1, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                 ^cmd5.sc:56: not found: value max\n",
      "    val layer1 = maxPool(max(conv2d(input.reshape(input.shape()(0), 3, 32, 32), weight1, bias1, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                         ^cmd5.sc:56: not found: value conv2d\n",
      "    val layer1 = maxPool(max(conv2d(input.reshape(input.shape()(0), 3, 32, 32), weight1, bias1, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                             ^cmd5.sc:57: not found: value maxPool\n",
      "    val layer2 = maxPool(max(conv2d(layer1, weight2, bias2, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                 ^cmd5.sc:57: not found: value max\n",
      "    val layer2 = maxPool(max(conv2d(layer1, weight2, bias2, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                         ^cmd5.sc:57: not found: value conv2d\n",
      "    val layer2 = maxPool(max(conv2d(layer1, weight2, bias2, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                             ^cmd5.sc:58: not found: value maxPool\n",
      "    val layer3 = maxPool(max(conv2d(layer2, weight3, bias3, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                 ^cmd5.sc:58: not found: value max\n",
      "    val layer3 = maxPool(max(conv2d(layer2, weight3, bias3, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                         ^cmd5.sc:58: not found: value conv2d\n",
      "    val layer3 = maxPool(max(conv2d(layer2, weight3, bias3, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                             ^cmd5.sc:59: not found: value maxPool\n",
      "    val layer4 = maxPool(max(conv2d(layer3, weight4, bias4, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                 ^cmd5.sc:59: not found: value max\n",
      "    val layer4 = maxPool(max(conv2d(layer3, weight4, bias4, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                         ^cmd5.sc:59: not found: value conv2d\n",
      "    val layer4 = maxPool(max(conv2d(layer3, weight4, bias4, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                             ^cmd5.sc:60: not found: value maxPool\n",
      "    val layer5 = maxPool(max(conv2d(layer4, weight5, bias5, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                 ^cmd5.sc:60: not found: value max\n",
      "    val layer5 = maxPool(max(conv2d(layer4, weight5, bias5, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                         ^cmd5.sc:60: not found: value conv2d\n",
      "    val layer5 = maxPool(max(conv2d(layer4, weight5, bias5, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
      "                             ^cmd5.sc:63: not found: value softmax\n",
      "    softmax(layer6)\n",
      "    ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "import hyperparameters.INDArrayWeight\n",
    "\n",
    "val weight1 = {\n",
    "    import org.nd4s.Implicits._\n",
    "    INDArrayWeight(Nd4j.randn(Array(16, 3, 3, 3)) / math.sqrt(3 * 3 * 3 / 2))\n",
    "}\n",
    "val bias1 = {\n",
    "    hyperparameters.INDArrayWeight(Nd4j.zeros(16))\n",
    "}\n",
    "\n",
    "val weight2 = {\n",
    "    import org.nd4s.Implicits._\n",
    "    INDArrayWeight(Nd4j.randn(Array(18, 16, 3, 3)) / math.sqrt(16 * 3 * 3 / 2))\n",
    "}\n",
    "val bias2 = {\n",
    "    hyperparameters.INDArrayWeight(Nd4j.zeros(18))\n",
    "}\n",
    "\n",
    "val weight3 = {\n",
    "    import org.nd4s.Implicits._\n",
    "    INDArrayWeight(Nd4j.randn(Array(20, 18, 3, 3)) / math.sqrt(18 * 3 * 3 / 2))\n",
    "}\n",
    "val bias3 = {\n",
    "    hyperparameters.INDArrayWeight(Nd4j.zeros(20))\n",
    "}\n",
    "\n",
    "val weight4 = {\n",
    "    import org.nd4s.Implicits._\n",
    "    INDArrayWeight(Nd4j.randn(Array(22, 20, 3, 3)) / math.sqrt(20 * 3 * 3 / 2))\n",
    "}\n",
    "val bias4 = {\n",
    "    hyperparameters.INDArrayWeight(Nd4j.zeros(22))\n",
    "}\n",
    "\n",
    "val weight5 = {\n",
    "    import org.nd4s.Implicits._\n",
    "    INDArrayWeight(Nd4j.randn(Array(24, 22, 3, 3)) / math.sqrt(22 * 3 * 3 / 2))\n",
    "}\n",
    "val bias5 = {\n",
    "    hyperparameters.INDArrayWeight(Nd4j.zeros(24))\n",
    "}\n",
    "\n",
    "\n",
    "val weight6 = {\n",
    "    import org.nd4s.Implicits._\n",
    "    INDArrayWeight(Nd4j.randn(Array(24, 10)) / math.sqrt(24 / 2))\n",
    "}\n",
    "val bias6 = {\n",
    "    hyperparameters.INDArrayWeight(Nd4j.zeros(10))\n",
    "}\n",
    "\n",
    "def myNeuralNetwork(input: INDArray): INDArrayLayer = {\n",
    "    import hyperparameters.max\n",
    "    import hyperparameters.maxPool\n",
    "    import hyperparameters.conv2d\n",
    "    val layer1 = maxPool(max(conv2d(input.reshape(input.shape()(0), 3, 32, 32), weight1, bias1, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
    "    val layer2 = maxPool(max(conv2d(layer1, weight2, bias2, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
    "    val layer3 = maxPool(max(conv2d(layer2, weight3, bias3, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
    "    val layer4 = maxPool(max(conv2d(layer3, weight4, bias4, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
    "    val layer5 = maxPool(max(conv2d(layer4, weight5, bias5, (3, 3), (1, 1), (1, 1)), 0.0), (2, 2))\n",
    "\n",
    "    val layer6 = layer5.reshape(input.shape()(0), 24) dot weight6 + bias6\n",
    "    softmax(layer6)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LossFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn about the prediction result of the neural network, we need to write the loss function `lossFunction`. We use [cross-entropy loss](https://en.wikipedia.org/wiki/Cross_entropy) to make comparison between this result and the actual result before return the score. Formula:\n",
    "![](https://zhihu.com/equation?tex=%5Cdisplaystyle+H%28p%2Cq%29%3D-%5Csum_xp%28x%29+logq%28x%29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd5.sc:1: not found: value hyperparameters\n",
      "import hyperparameters.DoubleLayer\n",
      "       ^cmd5.sc:3: not found: type DoubleLayer\n",
      "def lossFunction(input: INDArray, expectOutput: INDArray): DoubleLayer = {\n",
      "                                                           ^cmd5.sc:3: not found: type INDArray\n",
      "def lossFunction(input: INDArray, expectOutput: INDArray): DoubleLayer = {\n",
      "                        ^cmd5.sc:3: not found: type INDArray\n",
      "def lossFunction(input: INDArray, expectOutput: INDArray): DoubleLayer = {\n",
      "                                                ^cmd5.sc:4: not found: value myNeuralNetwork\n",
      "    val probabilities = myNeuralNetwork(input)\n",
      "                        ^cmd5.sc:5: not found: value hyperparameters\n",
      "    -(hyperparameters.log(probabilities) * expectOutput).mean\n",
      "      ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "import hyperparameters.DoubleLayer\n",
    "\n",
    "def lossFunction(input: INDArray, expectOutput: INDArray): DoubleLayer = {\n",
    "    val probabilities = myNeuralNetwork(input)\n",
    "    -(hyperparameters.log(probabilities) * expectOutput).mean\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the images and corresponding label information for test data from CIFAR10 database and process them, we need [`import $file.ReadCIFAR10ToNDArray`](https://github.com/ThoughtWorksInc/DeepLearning.scala-website/blob/master/ipynbs/ReadCIFAR10ToNDArray.sc). This is a script file containing the read and processed CIFAR10 data, provided in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                 \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.etl.Cifar10\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.future._\n",
       "\u001b[39m\n",
       "\u001b[36mcifar10\u001b[39m: \u001b[32mcom\u001b[39m.\u001b[32mthoughtworks\u001b[39m.\u001b[32mdeeplearning\u001b[39m.\u001b[32metl\u001b[39m.\u001b[32mCifar10\u001b[39m = \u001b[33mCifar10\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// import $url.{`https://raw.githubusercontent.com/ThoughtWorksInc/DeepLearning.scala-website/v1.0.0-doc/ipynbs/ReadCIFAR10ToNDArray.sc` => ReadCIFAR10ToNDArray}\n",
    "\n",
    "// val trainNDArray = ReadCIFAR10ToNDArray.readFromResource(\"/cifar-10-batches-bin/data_batch_1.bin\", 1000)\n",
    "\n",
    "// val testNDArray = ReadCIFAR10ToNDArray.readFromResource(\"/cifar-10-batches-bin/test_batch.bin\", 100)\n",
    "\n",
    "import $ivy.`com.thoughtworks.deeplearning.etl::cifar10:1.0.1`\n",
    "import com.thoughtworks.deeplearning.etl.Cifar10\n",
    "import com.thoughtworks.future._\n",
    "val cifar10 = Cifar10.load().blockingAwait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before passing data to the softmax classifier, we first process label data with ([one hot encoding](https://en.wikipedia.org/wiki/One-hot)): transform INDArray of `NumberOfPixels Ã— 1` into INDArray of `NumberOfPixels Ã— NumberOfClasses`. The value of correct classification corresponding to each line is 1, and the values of other columns are 0. The reason for differentiating the training set and test set is to make it clear that whether the network is over trained which leads to [overfitting](https://en.wikipedia.org/wiki/Overfitting). While processing label data, we used [Utils](https://github.com/ThoughtWorksInc/DeepLearning.scala-website/blob/master/ipynbs/Utils.sc), which is also provided in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// val trainData = trainNDArray.head\n",
    "// val testData = testNDArray.head\n",
    "\n",
    "// val trainExpectResult = trainNDArray.tail.head\n",
    "// val testExpectResult = testNDArray.tail.head\n",
    "\n",
    "// import $url.{`https://raw.githubusercontent.com/ThoughtWorksInc/DeepLearning.scala-website/v1.0.0-doc/ipynbs/Utils.sc` => Utils}\n",
    "\n",
    "// val vectorizedTrainExpectResult = Utils.makeVectorized(trainExpectResult, NumberOfClasses)\n",
    "// val vectorizedTestExpectResult = Utils.makeVectorized(testExpectResult, NumberOfClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To observe the training process of the neural network, we need to output `loss`; while training the neural network, the `loss` shall be decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd6.sc:10: type mismatch;\n",
      " found   : scala.collection.mutable.Buffer[Float]\n",
      " required: IndexedSeq[Float]\n",
      "    def lossSeq: IndexedSeq[Float] = lossBuffer\n",
      "                                     ^cmd6.sc:12: not found: value Scatter\n",
      "    def poltLoss(): Unit = Seq(Scatter(lossSeq.indices, lossSeq)).plot(title = \"loss by time\")\n",
      "                               ^cmd6.sc:12: not found: value title\n",
      "    def poltLoss(): Unit = Seq(Scatter(lossSeq.indices, lossSeq)).plot(title = \"loss by time\")\n",
      "                                                                       ^cmd6.sc:18: not found: type monadic\n",
      "        @monadic[Future]\n",
      "         ^cmd6.sc:21: value foreach is not a member of scalaz.EphemeralStream[Int]\n",
      "            for (epoch <- 0 |=> numberOfEpoches) {\n",
      "                            ^cmd6.sc:25: not found: value lossFunction\n",
      "                    val loss = lossFunction(batch, labels).train.each\n",
      "                               ^cmd6.sc:27: not found: value hyperparameters\n",
      "                    hyperparameters.logger.info(s\"epoch=$epoch iteration=$i batchSize=$batchSize loss=$loss\")\n",
      "                    ^cmd6.sc:30: not found: value hyperparameters\n",
      "            hyperparameters.logger.info(\"Done\")\n",
      "            ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "// var lossSeq: IndexedSeq[Double] = IndexedSeq.empty\n",
    "\n",
    "// @monadic[Future]\n",
    "// val trainTask: Future[Unit] = {\n",
    "//   val lossStream = for (_ <- (1 to 2000).toStream) yield {\n",
    "//     val loss = lossFunction(trainData, vectorizedTrainExpectResult).train.each\n",
    "//     kernel.publish.markdown(s\"loss: $loss\")\n",
    "//     loss\n",
    "//   }\n",
    "//   lossSeq = IndexedSeq.concat(lossStream)\n",
    "// }\n",
    "\n",
    "import scalaz.std.anyVal._\n",
    "import scalaz.syntax.all._\n",
    "\n",
    "class Trainer(batchSize: Int, numberOfEpoches: Int = 5) {\n",
    "    @volatile\n",
    "    private var isShuttingDown: Boolean = false\n",
    "\n",
    "    private val lossBuffer = scala.collection.mutable.Buffer.empty[Float]\n",
    "    \n",
    "    def lossSeq: IndexedSeq[Float] = lossBuffer\n",
    "    \n",
    "    def poltLoss(): Unit = Seq(Scatter(lossSeq.indices, lossSeq)).plot(title = \"loss by time\")\n",
    "    \n",
    "    def interrupt(): Unit = isShuttingDown = true\n",
    "\n",
    "    def startTrain(): Unit = {\n",
    "\n",
    "        @monadic[Future]\n",
    "        def trainTask: Future[Unit] = {\n",
    "            isShuttingDown = false\n",
    "            for (epoch <- 0 |=> numberOfEpoches) {\n",
    "                val iterator = cifar10.epoch(batchSize).zipWithIndex\n",
    "                while (iterator.hasNext && !isShuttingDown) {\n",
    "                    val (Cifar10.Batch(labels, batch), i) = iterator.next()\n",
    "                    val loss = lossFunction(batch, labels).train.each\n",
    "                    lossBuffer += loss\n",
    "                    hyperparameters.logger.info(s\"epoch=$epoch iteration=$i batchSize=$batchSize loss=$loss\")\n",
    "                }\n",
    "            }\n",
    "            hyperparameters.logger.info(\"Done\")\n",
    "        }\n",
    "\n",
    "        trainTask.onComplete { tryUnit: scala.util.Try[Unit] => tryUnit.get }\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd6.sc:1: not found: type Trainer\n",
      "val trainer = new Trainer(batchSize = 32, numberOfEpoches = 300)\n",
      "                  ^cmd6.sc:1: not found: value batchSize\n",
      "val trainer = new Trainer(batchSize = 32, numberOfEpoches = 300)\n",
      "                          ^cmd6.sc:1: not found: value numberOfEpoches\n",
      "val trainer = new Trainer(batchSize = 32, numberOfEpoches = 300)\n",
      "                                          ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "val trainer = new Trainer(batchSize = 32, numberOfEpoches = 300)\n",
    "trainer.startTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd6.sc:1: not found: value trainer\n",
      "val res6 = trainer.interrupt()\n",
      "           ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "//\n",
    "trainer.interrupt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict  your Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the processed test data to verify the prediction result of the neural network and compute the accuracy. The accuracy shall be about 32%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd6.sc:1: not found: value Await\n",
      "val predictResult = Await.result(myNeuralNetwork(testData).predict.toScalaFuture, Duration.Inf)\n",
      "                    ^cmd6.sc:1: not found: value myNeuralNetwork\n",
      "val predictResult = Await.result(myNeuralNetwork(testData).predict.toScalaFuture, Duration.Inf)\n",
      "                                 ^cmd6.sc:1: not found: value testData\n",
      "val predictResult = Await.result(myNeuralNetwork(testData).predict.toScalaFuture, Duration.Inf)\n",
      "                                                 ^cmd6.sc:1: not found: value Duration\n",
      "val predictResult = Await.result(myNeuralNetwork(testData).predict.toScalaFuture, Duration.Inf)\n",
      "                                                                                  ^cmd6.sc:2: not found: value Utils\n",
      "val res6_1 = println(\"The accuracy is \" + Utils.getAccuracy(predictResult,testExpectResult) + \"%\")\n",
      "                                          ^cmd6.sc:2: not found: value testExpectResult\n",
      "val res6_1 = println(\"The accuracy is \" + Utils.getAccuracy(predictResult,testExpectResult) + \"%\")\n",
      "                                                                          ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "val predictResult = Await.result(myNeuralNetwork(testData).predict.toScalaFuture, Duration.Inf)\n",
    "println(\"The accuracy is \" + Utils.getAccuracy(predictResult,testExpectResult) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.poltLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We have learned the follows in this article:\n",
    "\n",
    "* Prepare and process CIFAR10 data\n",
    "* Write softmax classifier\n",
    "* Use the prediction image of the neural network written by softmax classifier to match with the probability of each category."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
